# T05: Assessment Interview Guide

**VersiÃ³n:** 2.2.1  
**Ãšltima ActualizaciÃ³n:** 2025-11-03  
**Compatibilidad:** KERNEL v2.2.x

**PropÃ³sito:** GuÃ­a estructurada entrevistas diagnÃ³stico organizacional (Fase 0)  
**DuraciÃ³n:** 60-90 min por stakeholder  
**Audiencia:** C-Suite, VPs, Team Leads, IC contributors

---

## âš ï¸ PREREQUISITOS

**Nivel Madurez MÃ­nimo:**
- âœ… **Sponsor ejecutivo comprometido** (C-level con mandate y budget)
- âœ… **Acceso a stakeholders clave** (al menos 8-12 entrevistas cross-functional)
- âœ… **Tiempo disponible** (4-6 semanas para diagnÃ³stico completo)
- âœ… **Apertura a cambio** (org dispuesta a actuar sobre findings)

**SeÃ±ales de Alerta - NO USAR si:**
- ğŸš« **Crisis activa** â†’ Ir directo a `A4_Implementacion.md` Â§0 Path 1-2 (estabilizaciÃ³n)
- ğŸš« **No hay sponsor real** â†’ Assessment serÃ¡ ignorado, waste of time
- ğŸš« **Resistencia cultural alta** â†’ Hacer readiness building primero (3-6 meses)
- ğŸš« **Org <20 personas** â†’ Assessment too heavy, usar diagnÃ³stico simplificado

**Si Dudas:**
- Ver `A4_Implementacion.md` Â§0 para determinar path correcto (crisis vs transformation)
- Ver `A1_Patrones.md` Â§9 P35 PreparaciÃ³n R1-R5 para score readiness
- Considerar assessment MVP (solo 4-5 entrevistas, 2 semanas) si recursos limitados

---

## BLOQUE 0: PRE-ASSESSMENT TRIAGE - 10 min

**âš ï¸ CRITICAL: Completar ANTES de diagnÃ³stico detallado para evitar AP33 (Transforming During Crisis)**

### P0.1 Crisis Indicators Check

> "Â¿La organizaciÃ³n enfrenta actualmente crisis financiera, de clientes o de talento?"

**Buscar seÃ±ales crÃ­ticas:**

ğŸš© **Financial Crisis:**
- Cash runway < 90 dÃ­as
- Burn rate acelerado (>20% MoM)
- Payroll at risk prÃ³ximos 2 meses
- Credit lines agotadas

ğŸš© **Customer/Citizen Crisis:**
- Churn rate > 20% annually
- NPS < 0 (mÃ¡s detractors que promoters)
- Key account losses (top 20% revenue)
- Service delivery failures > 20% (sector pÃºblico)

ğŸš© **Talent Crisis:**
- Voluntary attrition > 25% annually
- High-performer exodus > 20%
- Leadership team departures (3+ in last quarter)
- eNPS < -10

**Decision Tree:**

```yaml
IF ANY crisis indicator present:
  Path: EMERGENCY STABILIZATION (A4 Â§0 Path 1-2)
  Action:
    1. STOP transformation assessment
    2. Activate P52 (Crisis Governance Pattern)
    3. Focus: Week 1-4 stabilization
    4. Re-assess H_Score Week 5
  Next_Step: Skip to crisis stabilization protocol
  
ELSE IF No crisis indicators:
  Path: STANDARD ASSESSMENT
  Action: Proceed to P0.2 Readiness Assessment
```

---

### P0.2 Change Readiness Assessment (if no crisis)

> "EvalÃºe 5 dimensiones de readiness para transformaciÃ³n (escala 1-5)"

**Dimensiones:**

1. **Leadership Alignment:** Â¿Executive team unificado sobre necesidad y approach?
   - 5: 100% alineados, total buy-in
   - 3: MayorÃ­a support, algunos skeptics
   - 1: Fragmentados, no consensus

2. **Urgency Level:** Â¿Existe caso compelling para cambiar AHORA?
   - 5: Burning platform claro OR opportunity window cerrando
   - 3: Change deseable pero no urgente
   - 1: Status quo aceptable

3. **Resource Availability:** Â¿Tiempo, dinero, personas disponibles?
   - 5: Resources totalmente allocated
   - 3: Resources disponibles pero constrained
   - 1: Zero capacity, org at limit

4. **Capability:** Â¿Skills para diseÃ±ar/implementar?
   - 5: Expertise in-house OR budget consultants
   - 3: Some skills, need upskilling
   - 1: No capability, no budget

5. **Organizational Bandwidth:** Â¿Capacidad absorber change?
   - 5: Utilization <80%, can absorb change
   - 3: Utilization 80-90%, tight but manageable
   - 1: Utilization >95%, overloaded

**Scoring & Decision:**

```yaml
Total_Score: [Sum of 5 dimensions] / 5 = [Average]

IF ALL dimensions >= 4:
  Recommendation: PROCEED full transformation
  Approach: A4 Â§1-Â§6 playbook standard
  Timeline: 12-18 months

ELSE IF MOST dimensions >= 3:
  Recommendation: PROCEED pilot/phased
  Approach: Start 1-2 teams, 3-month pilot
  Timeline: 6 months pilot, then re-assess

ELSE IF ANY dimension < 3:
  Recommendation: BUILD READINESS first
  Action: Address gaps (workshops, capacity, hiring)
  Re-assess: 3-6 months
  Risk: 70% failure if force now (AP32)

ELSE IF ANY dimension = 1:
  Recommendation: DELAY transformation
  Action: Prerequisites work only
  Timeline: 6-12 months readiness building
```

---

### P0.3 Building Blocks Completeness Check

> "Â¿La organizaciÃ³n tiene las 5 funciones organizacionales crÃ­ticas?"

**Checklist (D1 Â§4 Building Blocks):**

â˜ **BB1 - Engineers (Innovadores):**  
   Â¿QuiÃ©n diseÃ±a productos/servicios nuevos? Â¿Capacity innovation?
   - âœ… Presente: Dedicated eng teams, R&D capacity
   - âš ï¸ DÃ©bil: Solo maintenance, zero innovation
   - âŒ Ausente: No engineering, todo outsourced

â˜ **BB2 - Service Providers (Operadores):**  
   Â¿QuiÃ©n opera sistemas day-to-day? Â¿Service delivery?
   - âœ… Presente: Ops teams, SRE, service desk
   - âš ï¸ DÃ©bil: Reactive only, firefighting
   - âŒ Ausente: No operations capability

â˜ **BB3 - Coordinators (Facilitadores):**  
   Â¿QuiÃ©n coordina standards, governance cross-org?
   - âœ… Presente: Architecture, PMO, standards bodies
   - âš ï¸ DÃ©bil: Informal coordination only
   - âŒ Ausente: Zero coordination, silos totales

â˜ **BB4 - Sales/Stakeholder Engagement:**  
   Â¿QuiÃ©n construye relationships, descubre opportunities?
   - Private: Sales, marketing, business development
   - Public: Stakeholder engagement, citizen services
   - âœ… Presente: Dedicated function
   - âš ï¸ DÃ©bil: Reactive only
   - âŒ Ausente: Disconnect from customers/stakeholders

â˜ **BB5 - Audit (Aseguradores):**  
   Â¿Oversight independent, compliance, risk?
   - âœ… Presente: Internal audit, compliance team
   - âš ï¸ DÃ©bil: Compliance-only, no proactive
   - âŒ Ausente: No controls, compliance failures

**Gap Analysis:**

```yaml
Missing_BB â†’ Structural gap diagnosis in D1 Arquitectura

Common_Gaps:
  - Startup sin BB5 (Audit): ComÃºn early-stage, acceptable si <50 personas
  - Public sector sin BB4 formal: Stakeholder engagement diluido en silos
  - Scale-up sin BB3: Coordination chaos, cada team su standard
```

---

## BLOQUE 1: ARQUITECTURA (D1) - 15 min

### P1.1 Estructura Organizacional
> "Describe cÃ³mo estÃ¡n organizados los equipos. Â¿CuÃ¡ntos equipos? Â¿QuÃ© tamaÃ±o? Â¿QuÃ© poseen?"

**Buscar:**
- âœ… Teams 5-8 personas, cross-funcionales, ownership producto/servicio
- âš ï¸ Teams >12 personas, especializados por funciÃ³n, ownership ambiguo
- ğŸš© Silos departamentales, handoffs mÃºltiples, ownership nulo

**Scoring:**
- 80-100: Team Topologies aplicado, Conway's Law respetado
- 50-79: Estructura razonable, algunos silos
- 0-49: Silos crÃ­ticos, AP05 violaciÃ³n Conway

### P1.2 Deuda TÃ©cnica
> "Â¿CÃ³mo medirÃ­an la salud tÃ©cnica del sistema? Â¿QuÃ© % cÃ³digo es legacy sin tests?"

**Buscar:**
- âœ… Î›<15%, tests coverage >80%, refactoring continuo
- âš ï¸ Î›=15-35%, tests 50-80%, refactoring ocasional
- ğŸš© Î›>35%, tests <50%, "don't touch, it works"

**Scoring:**
- 80-100: Tech debt gestionado, Î›<15%
- 50-79: Tech debt moderado, Î›=15-35%
- 0-49: Tech debt crÃ­tico, Î›>35%

### P1.3 Dependencies
> "Â¿CuÃ¡ntos otros equipos debe coordinar su equipo para entregar una feature?"

**Buscar:**
- âœ… 0-1 dependencias, equipos autÃ³nomos
- âš ï¸ 2-3 dependencias, coordinaciÃ³n manejable
- ğŸš© >3 dependencias, coordinaciÃ³n constante

---

## BLOQUE 2: PERCEPCIÃ“N (D2) - 15 min

### P2.1 Observabilidad
> "Â¿CÃ³mo saben que el sistema estÃ¡ sano? Â¿QuÃ© dashboards existen? Â¿QuiÃ©n los usa?"

**Buscar:**
- âœ… Dashboards tiempo real, alertas proactivas, SLOs definidos
- âš ï¸ Logs centralizados, alertas bÃ¡sicas, revisiÃ³n manual
- ğŸš© Logs dispersos, alertas reactivas, "users report bugs"

### P2.2 Datos de Negocio
> "Â¿CÃ³mo miden satisfacciÃ³n cliente? Â¿Frecuencia? Â¿Accionabilidad?"

**Buscar:**
- âœ… NPS/CSAT continuo, analytics real-time, decisiones data-driven
- âš ï¸ Surveys trimestrales, analytics batch, intuiciÃ³n + datos
- ğŸš© Sin mediciÃ³n sistemÃ¡tica, decisiones basadas en anecdotes

### P2.3 Flujo Trabajo
> "Â¿DÃ³nde estÃ¡n los cuellos de botella? Â¿CÃ³mo lo saben?"

**Buscar:**
- âœ… WIP limits, cycle time tracked, bottlenecks identificados/resueltos
- âš ï¸ Tracking manual, bottlenecks conocidos pero no resueltos
- ğŸš© Sin visibilidad WIP, "siempre estamos ocupados"

---

## BLOQUE 2.5: AWARENESS & AUTOMATION MATURITY - 15 min

**âš¡ Nuevo en v1.3:** Evaluar madurez en niveles awareness (S1-S3) y automation (D1-D4)

### P2.5.1 Awareness Levels Evaluation (S1-S3)

> "EvalÃºe capacidad organizacional para percibir, comprender y proyectar estado del sistema"

**S1 - DETECT (Percibir):**

```yaml
Checklist:
  â˜ Â¿Dashboards con mÃ©tricas bÃ¡sicas disponibles 24/7?
  â˜ â˜ Â¿Alerting automated para eventos crÃ­ticos?
  â˜ Â¿Telemetry real-time o near-real-time (<1 min)?
  â˜ Â¿Logs aggregated y searchable (Ãºltimos 30 dÃ­as)?
  â˜ Â¿Monitoring coverage >90% systems crÃ­ticos?

Scoring (1-5):
  5: Full coverage, real-time, automated
  3: Partial coverage, gaps en monitoring
  1: Manual tracking, dashboards stale

Score_S1: [___] / 5
```

**S2 - COMPREHEND (Comprender):**

```yaml
Checklist:
  â˜ Â¿H_Score u otra mÃ©trica composite calculada automÃ¡ticamente?
  â˜ Â¿Alerting context-aware (no solo raw thresholds)?
  â˜ Â¿Observables O1-O8, IN1-IN3 tracked y visibles?
  â˜ Â¿Pattern recognition automated (anomaly detection)?
  â˜ Â¿Alert quality >80% (actionable, no noise)?

Scoring (1-5):
  5: H_Score automated, intelligent alerting, pattern detection
  3: Some synthesis, alerts basic pero functional
  1: Solo raw metrics, mucho noise en alerts

Score_S2: [___] / 5
```

**S3 - PROJECT (Proyectar):**

```yaml
Checklist:
  â˜ Â¿Forecasting trends implemented? (revenue, churn, capacity)
  â˜ Â¿Crisis thresholds monitoreados con alerts? (H_Score<45)
  â˜ Â¿Scenario planning tools available? (Monte Carlo, what-if)
  â˜ Â¿Predictive models en production? (â‰¥3 models)
  â˜ Â¿Forecast accuracy <15% MAPE?

Scoring (1-5):
  5: Multiple forecasts, scenario planning, high accuracy
  3: Basic forecasting, emergent predictive capability
  1: No prediction, purely reactive

Score_S3: [___] / 5
```

**Awareness_Maturity_Overall:**
```
Score = (S1 Ã— 20) + (S2 Ã— 20) + (S3 Ã— 20) = [___] / 100

InterpretaciÃ³n:
  >80: Excelente - Full spectrum awareness
  60-80: Bueno - S1+S2 strong, S3 developing
  40-60: AtenciÃ³n - Solo S1, gaps significativos
  <40: CrÃ­tico - Awareness bÃ¡sica insuficiente
```

---

### P2.5.2 Decision Automation Evaluation (D1-D4)

> "EvalÃºe quÃ© decisiones estÃ¡n automated vs requieren humanos"

**D1 - DIRECT FEEDBACK (AutomÃ¡tica):**

```yaml
Question: "Liste 5-10 decisiones que ocurren automÃ¡ticamente sin intervenciÃ³n humana"

Ejemplos_Esperados:
  - Autoscaling (CPU>80% â†’ add instances)
  - Circuit breakers (error rate>10% â†’ open circuit)
  - Auto-remediation (pod crash â†’ restart)
  - Fraud rules bÃ¡sicas (amount>$10K â†’ flag)

Count_D1: [___] decisiones automated

Automation_D1_Rate:
  = Count_D1 / Total_D1_Opportunities
  Estimate: [___]% (target >60%)
```

**D2 - RULE-BASED (Condicional):**

```yaml
Question: "Â¿QuÃ© business rules estÃ¡n documentadas? Â¿Automated?"

Checklist:
  â˜ Approval workflows documented (>$X require VP)
  â˜ Compliance rules automated (GDPR, SOX)
  â˜ Quality gates CI/CD (coverage>80%, security scan)
  â˜ Triage rules (severity â†’ priority mapping)
  â˜ Rules engine deployed (Drools, decision tables)

Rules_Coverage:
  = # rules_documented / # critical_decision_types
  Estimate: [___]% (target >90%)

Rules_Automation:
  = # rules_automated / # rules_documented
  Estimate: [___]% (target >75%)
```

**D3 - ASSOCIATIVE (ML-based):**

```yaml
Question: "Â¿QuÃ© ML models estÃ¡n en producciÃ³n sirviendo decisiones?"

List_Models:
  1. [Model name] - [Decision served] - [Accuracy]
  2. ...
  3. ...

Count_D3: [___] ML models in production (target 5-10)

Human_Validation_Rate:
  Â¿QuÃ© % decisiones D3 validated by human?
  Estimate: [___]% (target >90% si high-risk)

Model_Monitoring:
  â˜ Drift detection active?
  â˜ Accuracy tracking automated?
  â˜ Explainability available (SHAP, LIME)?
```

**D4 - KNOWLEDGE-BASED (AnalÃ­tica):**

```yaml
Question: "Â¿CuÃ¡nto tardan decisiones estratÃ©gicas/tÃ¡cticas?"

Decision_Latency:
  - Strategic (portfolio, roadmap): [___] dÃ­as (target <7d)
  - Tactical (feature prioritization): [___] horas (target <24h)

Simulation_Tools:
  â˜ Monte Carlo simulation available?
  â˜ Scenario planning structured process?
  â˜ What-if analysis tools deployed?

OKR_Structure:
  â˜ Strategic decisions linked to OKRs?
  Estimate: [___]% decisions con OKR linkage (target >80%)
```

**Decision_Automation_Overall:**
```
Automation_Rate = % decisiones repeatables que estÃ¡n automated

Estimate: [___]% (based on D1-D3 counts above)

Benchmark:
  >50%: Excelente - Alta automation apropiada
  30-50%: Bueno - Balance automation/human
  15-30%: AtenciÃ³n - Underautomated, opportunities
  <15%: CrÃ­tico - Manual decision overload
```

---

## BLOQUE 3: DECISIÃ“N (D3) - 20 min

### P3.1 Planning
> "Describan su proceso planificaciÃ³n. Â¿Freuencia? Â¿QuiÃ©n participa? Â¿CÃ³mo priorizan?"

**Buscar:**
- âœ… OKRs trimestrales, bottom-up + top-down, value-driven prioritization
- âš ï¸ Planning semestral, top-down, priorizaciÃ³n mixta
- ğŸš© Planning anual, cascada, "todo es prioridad 1"

### P3.2 Adaptabilidad
> "Â¿QuÃ© pasa si aparece oportunidad urgente mid-quarter? Â¿Pueden pivotar?"

**Buscar:**
- âœ… 30% capacidad emergente, re-planificaciÃ³n 2 semanas
- âš ï¸ 10-20% buffer, re-planificaciÃ³n mensual
- ğŸš© 0% buffer, "committed for the year"

### P3.3 Alignment
> "Â¿Todos entienden el 'por quÃ©' de su trabajo? Â¿ConexiÃ³n con objetivos empresa?"

**Buscar:**
- âœ… Transparencia completa OKRs, todos explican why
- âš ï¸ OKRs compartidos, entendimiento variable
- ğŸš© "Work comes from backlog, don't ask why"

---

## BLOQUE 4: OPERACIÃ“N (D4) - 20 min

### P4.1 Velocity
> "Â¿CuÃ¡nto tardan features typical de concebir a producciÃ³n?"

**Buscar:**
- âœ… Lead time <2 semanas, velocity estable/creciente
- âš ï¸ Lead time 2-8 semanas, velocity errÃ¡tica
- ğŸš© Lead time >8 semanas, velocity decreciente

### P4.2 Quality
> "Â¿CuÃ¡ntos incidents producciÃ³n/mes? Â¿MTTR?"

**Buscar:**
- âœ… <2 incidents/mes, MTTR <1hr
- âš ï¸ 2-5 incidents/mes, MTTR 1-4hrs
- ğŸš© >5 incidents/mes, MTTR >4hrs

### P4.3 Morale
> "En escala 1-10, Â¿quÃ© tan satisfecho estÃ¡ el equipo? Â¿Por quÃ©?"

**Buscar:**
- âœ… 8-10: EnergÃ­a alta, ownership, aprendizaje
- âš ï¸ 5-7: Neutral, algunas frustraciones
- ğŸš© 1-4: Burnout, sÃ­ntomas turnover

---

## BLOQUE 5: IA & AUTOMATIZACIÃ“N - 10 min

### P5.1 Nivel Madurez IA
> "Â¿QuÃ© procesos tienen automatizaciÃ³n IA? Â¿Agentes digitales en equipos?"

**Buscar:**
- âœ… Agentes M4-M6, automatizaciÃ³n 30%+ tareas, MLOps maduro
- âš ï¸ Pilots IA, automatizaciÃ³n 10-30%, MLOps incipiente
- ğŸš© Sin IA, automatizaciÃ³n <10%, scripts manuales

### P5.2 DelegaciÃ³n Humano-IA
> "Â¿CÃ³mo deciden quÃ© delegar a agentes IA vs humanos?"

**Buscar:**
- âœ… Matriz delegaciÃ³n definida, evaluaciÃ³n sistemaÃ¡tica
- âš ï¸ Ad-hoc, basado en disponibilidad
- ğŸš© "No usamos IA" o "IA hace todo"

---

## CÃLCULO H_SCORE

```python
# Scoring por dominio (0-100)
D1_Arquitectura = (P1.1 + P1.2 + P1.3) / 3
D2_Percepcion = (P2.1 + P2.2 + P2.3) / 3
D3_Decision = (P3.1 + P3.2 + P3.3) / 3
D4_Operacion = (P4.1 + P4.2 + P4.3) / 3

# H_Score total (promedio ponderado)
H_Score = (
    D1_Arquitectura * 0.30 +  # MÃ¡s peso: fundaciÃ³n
    D2_Percepcion * 0.20 +
    D3_Decision * 0.25 +
    D4_Operacion * 0.25
)

# InterpretaciÃ³n
if H_Score >= 75:
    nivel = "EXCELENTE - OptimizaciÃ³n continua"
elif H_Score >= 60:
    nivel = "BUENO - Mejora incremental"
elif H_Score >= 45:
    nivel = "ACEPTABLE - TransformaciÃ³n viable"
else:
    nivel = "CRÃTICO - EstabilizaciÃ³n urgente"
```

---

## NOTAS PARA INTERVIEWER

1. **Triangular datos:** Entrevistar 3-5 personas por dominio (C-level, middle mgmt, ICs)
2. **Buscar evidencia:** No aceptar claims sin mÃ©tricas/ejemplos
3. **Detectar deseabilidad social:** Preguntar "cÃ³mo", no "si hacen X"
4. **Observar lenguaje:** "We should..." vs "We do..." indica gaps
5. **Capturar quotes:** Usar verbatims en reporte final

---

**Output esperado:** Report 5-10 pÃ¡ginas con H_Score, breakdown por dominio, top 5 hallazgos crÃ­ticos, roadmap sugerido.