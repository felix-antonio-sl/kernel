# E7_Enterprise_Technology_Integration

**Versi√≥n:** 2.0.0  
**Estado:** Production  
**Audiencia:** CTOs, Arquitectos SI, Tech Leads, Platform Engineers  
**Dependencias**: CORE/01-08, DOMINIOS/D1-D4, APLICACION/A1-A5

---

## ¬ß1. PROP√ìSITO Y SCOPE

### Definici√≥n

Este dominio especializado cubre el **desarrollo de aplicaciones empresariales end-to-end** y la habilitaci√≥n tecnol√≥gica de plataformas (DevOps, security, observability, UX/UI). Integra patrones arquitect√≥nicos modernos, stacks tecnol√≥gicos, ingenier√≠a de plataformas y experiencia de usuario como capa transversal.

### Alcance

**INCLUYE**:

- Patrones arquitect√≥nicos (Monolito Modular, Microservicios, EDA, Serverless)
- Stack tecnol√≥gico enterprise (backend, frontend, databases, infra)
- Experience Layer (UX/UI patterns, AI-assisted UX, design systems, multi-device)
- DevOps & Platform Engineering (CI/CD, IaC, containerization, observability)
- Security shift-left (autenticaci√≥n, autorizaci√≥n, OWASP, secrets management)
- NFRs & SLOs (latency, throughput, availability, C4, ADRs)

**EXCLUYE** (cubiertos por otros dominios):

- Data-as-Product, AI Orchestration, Process Automation, Knowledge Management ‚Üí **E8_Intelligent_Systems**
- Dominio-espec√≠fico (gobierno, manufactura, salud, finanzas) ‚Üí **E2-E5**
- Foundation concepts ‚Üí **CORE** (Recurso, Flujo, Actor, L√≠mite en CORE/01-03)

### Conexi√≥n KERNEL

**Primitivos especializados**:

- **Recurso**: Applications, tech stack, infrastructure, platform services
- **Flujo**: CI/CD pipelines, user workflows, data flows, deployment flows
- **Actor**: Developers, SRE/DevOps Engineers, Platform Engineers, End-users
- **L√≠mite**: NFRs, SLOs, API contracts, regulatory constraints, error budgets

**Dominios extendidos**:

- **D1_Arquitectura**: Stack patterns, Conway's Law, ADRs, bounded contexts
- **D2_Percepci√≥n**: Tech observability (DORA metrics, tech health, uptime)
- **D3_Decisi√≥n**: Stack selection framework, trade-offs analysis, build vs buy
- **D4_Operaci√≥n**: CI/CD execution, deployment strategies, SRE practices

**Delegaci√≥n tech-specific**:

- **M2-M3**: AI copilots en UX (inform users, enable capabilities) ‚Üí ¬ß4.5
- **M4-M6**: Automated testing, quality gates, automated deployments ‚Üí ¬ß5

---

## ¬ß2. PATRONES ARQUITECT√ìNICOS

### Trade-Offs Matrix

La elecci√≥n arquitect√≥nica es la decisi√≥n con mayor impacto a largo plazo. No existe soluci√≥n √∫nica; la clave es entender los **trade-offs**.

| Patr√≥n | Ideal Para | Ventajas Clave | Desventajas/Consideraciones |
|:---|:---|:---|:---|
| **Monolito Modular** | Startups, MVPs, equipos <15, dominios acotados | ‚Ä¢ Simplicidad inicial desarrollo/deploy<br>‚Ä¢ Rendimiento optimizado (in-process)<br>‚Ä¢ Refactorizaci√≥n interna f√°cil | ‚Ä¢ Acoplamiento tecnol√≥gico<br>‚Ä¢ Escalado granular dif√≠cil<br>‚Ä¢ Ciclos deploy lentos al crecer |
| **Microservicios** | Sistemas complejos, equipos >30 distribuidos, escalabilidad granular | ‚Ä¢ Escalabilidad por componente<br>‚Ä¢ Autonom√≠a equipos<br>‚Ä¢ Deploys independientes frecuentes | ‚Ä¢ Complejidad operacional (orchestration, service discovery)<br>‚Ä¢ Consistencia eventual (Sagas, Outbox)<br>‚Ä¢ Latencia de red, tracing distribuido (OpenTelemetry) |
| **EDA (Event-Driven)** | Procesos as√≠ncronos, alta desacoplaci√≥n, sistemas reactivos (IoT, finanzas) | ‚Ä¢ Desacoplamiento m√°ximo<br>‚Ä¢ Escalabilidad masiva<br>‚Ä¢ Resiliencia a picos de carga | ‚Ä¢ Debugging flujos complejo<br>‚Ä¢ Requiere message broker robusto (Kafka, Pulsar)<br>‚Ä¢ Idempotencia, orden de eventos cr√≠ticos |
| **Serverless (FaaS)** | Cargas intermitentes, event-driven, APIs bajo tr√°fico, prototipos | ‚Ä¢ Coste cero en reposo (pay-per-use)<br>‚Ä¢ Escalado autom√°tico gestionado<br>‚Ä¢ Abstracci√≥n infra total | ‚Ä¢ Cold starts (latencia)<br>‚Ä¢ L√≠mites tiempo/recursos ejecuci√≥n<br>‚Ä¢ Vendor lock-in, testing local complejo |

### Principio Rector

**Start monolito modular bien estructurado** ‚Üí Extract microservicios cuando **dolor del acoplamiento > complejidad de la distribuci√≥n**.

**Domain-Driven Design (DDD)**: Define **Bounded Contexts** como l√≠mites naturales para m√≥dulos/servicios.

**Conexi√≥n KERNEL**:

- **P06 Inverse Conway's Law** (APLICACION/A1): Org structure ‚Üí System architecture
- **D1_Arquitectura ¬ß1 P4**: Conway's Law awareness expl√≠cito
- **L√≠mite** (CORE/03): Bounded contexts como l√≠mites sem√°nticos

### Decisi√≥n Framework

**Inputs**: NFRs + Team skills + Ecosystem maturity  
**Proceso**: Evaluar trade-offs tabla ‚Üí Piloto peque√±o ‚Üí Iterar  
**Output**: ADR documentado (T13_ADR template, REFERENCIA/R6_Templates)

**Ejemplo aplicaci√≥n**: Startup 10 eng ‚Üí 50 eng:

1. A√±o 1: Monolito modular (velocidad m√°xima)
2. A√±o 2-3: Identificar bounded contexts con dolor (deploy freq bottleneck)
3. A√±o 3: Extraer 2-3 microservicios cr√≠ticos (pagos, autenticaci√≥n)
4. A√±o 4: Deploy freq 1 cada 3 semanas ‚Üí 5/d√≠a (DORA improvement)

---

## ¬ß3. STACK TECNOL√ìGICO

### Decision Framework

**Criterios**: Ecosistema + Talento disponible + NFRs + Madurez

### Backend

| Lenguaje/Framework | Ideal Para | Justificaci√≥n |
|:---|:---|:---|
| **Java (Spring Boot, Quarkus)** | Apps enterprise robustas, alto rendimiento, arquitecturas complejas | Ecosistema maduro, tipado fuerte, tooling excepcional, talent pool amplio |
| **C# (.NET)** | Ecosistemas Microsoft, integraci√≥n Azure nativa | Alto rendimiento, unificado (web/desktop/mobile), excelente DX |
| **Python (Django, FastAPI)** | Apps data-intensive, servicios IA/ML | Rapidez desarrollo, FastAPI performance comparable Go/Node, ecosistema ML/AI |
| **Node.js (Express, NestJS)** | Apps I/O-bound, real-time (websockets) | Event loop non-blocking, ecosistema NPM masivo, NestJS estructura modular |
| **Go** | Microservicios alto rendimiento, CLI/infra tools | Concurrencia nativa simple, binarios est√°ticos, footprint bajo |

### Frontend

| Framework | Trade-off | Cu√°ndo Usar |
|:---|:---|:---|
| **React** | Flexibilidad vs Estructura | Equipos que prefieren componer su framework (routing, state management custom) |
| **Angular** | Estructura vs Flexibilidad | Apps enterprise grandes, estructura robusta, DI, tipado fuerte desde inicio |
| **Vue.js** | Equilibrio | Curva aprendizaje suave, balance React flexibility + Angular structure |
| **Svelte/SolidJS** | Performance vs Ecosystem | Interfaces altamente interactivas, performance m√°ximo (compiladores, minimal JS) |

### Databases

| Tipo | Tecnolog√≠a | Uso Principal |
|:---|:---|:---|
| **SQL (OLTP)** | PostgreSQL (default), MySQL | Datos transaccionales, ACID, extensibilidad (JSONB, PostGIS) |
| **NoSQL Documental** | MongoDB, DynamoDB | Datos semi-estructurados, esquemas flexibles, escalabilidad horizontal |
| **Cache** | Redis | Cach√© in-memory, pub/sub, colas, latency reduction |
| **Search** | Elasticsearch, OpenSearch | B√∫squeda full-text, analytics, observability (logs, metrics) |

### Conexi√≥n KERNEL

**Recurso (CORE/01)**: Stack como capacidad habilitadora (tech capacity R3)  
**Flujo (CORE/02)**: CI/CD como flujo automatizado (F2 Automated)  
**Actor (CORE/03)**: Developers, SRE como actores especializados  
**D3_Decisi√≥n ¬ß3**: Stack selection como decisi√≥n arquitect√≥nica bajo incertidumbre

---

## ¬ß4. EXPERIENCE LAYER (UX/UI Integrado)

### ¬ß4.1 Modern Layouts & Design Patterns

**Modular, Card-Based Interfaces**:

- Dashboards modulares con widgets movibles (personalizaci√≥n usuario)
- Drill-down sin overhead cognitivo (progressive disclosure)
- Beneficio: Updates componentes no disrumpten sistema completo

**Progressive Disclosure & Contextual Help**:

- Opciones avanzadas ocultas hasta necesarias (reduce cognitive load)
- Tooltips contextuales, info panels on-demand
- **Ejemplo**: Analytics app muestra summary simple ‚Üí "Show Advanced Filters" expande

**Micro-Interactions for Feedback**:

- Animaciones sutiles (buttons hover, loaders, checkmarks post-save)
- Instant feedback usuarios (acci√≥n registrada)
- **Ejemplo enterprise**: Field validations shake/color-highlight on error

**Established UI Patterns**:

- Leverage consumer patterns (left-side menus, top search bars)
- Reducen training time (users recognize behavior)
- **Principio**: Consistency builds trust (mission-critical tools)

**Minimalist Aesthetics**:

- Whitespace amplio, typography clara, color deliberado
- **Dark mode** default (reduce eye strain, hours-in-dashboards use case)
- **Filosof√≠a**: Less is more ‚Üí Data y acciones destacan

**Conexi√≥n KERNEL**:

- **D2_Percepci√≥n O1**: UX clarity como observable (P1 Perceptualidad CORE/05 ¬ß3)
- **A3_Diagn√≥stico ¬ß4**: UX friction assessment

### ¬ß4.2 Interaction Models

**Real-Time Collaboration**:

- Multi-user live editing (cursors, edits real-time como Google Docs/Figma)
- **Baseline expectation 2024**: Project mgmt, analytics tools con co-editing
- **Ejemplo**: Joint annotation de dashboards durante meetings

**Conversational & Chatbot Interfaces**:

- Natural language requests vs menu hunting
- **Ejemplo**: "What was Q3 revenue growth?" ‚Üí AI-driven answer
- **CRM use case**: Chatbot retrieve customer info, draft emails (speed workflows)

**Voice & Screen-Free Controls**:

- VUI para field workers (hands-free, mobility)
- **Ejemplo**: Warehouse app usa "next item" voice command
- **Emergente**: AR glasses maintenance/training (hands-free data viz)

**Keyboard Shortcuts & Command Palettes**:

- Power-users efficiency (Ctrl+K universal search)
- **Inspired by**: VS Code, Slack command palettes
- **Ejemplo**: Type "inv" ‚Üí Suggests "Invite User", "Invoice Settings"

**Non-Linear Workflows**:

- Expert users no siguen "happy path" preset
- Save draft workflows, resume later, multiple paths to function
- **Ejemplo**: Edit dos records side-by-side (parallel workstreams)

**Delightful UX & Gamification**:

- Progress indicators celebrate completion (reduce stress)
- **Ejemplo**: Asana unicorn animation task completion, confetti milestones
- **Beneficio**: Boost morale, positive emotional connection (Zoom fatigue mitigation)

**Conexi√≥n KERNEL**:

- **M2-M3 Delegaci√≥n** (CORE/04 ¬ß8): AI copilots como M3 Enable (conversational interfaces)
- **D4_Operaci√≥n A2**: User workflows como ejecuci√≥n especificada
- **P55 Conversational Interface** (APLICACION/A1): Pattern relacionado

### ¬ß4.3 Accessibility & Inclusive Design

**Accessibility as Standard (WCAG Baseline)**:

- WCAG AA baseline, AAA aspirational
- **Valor amplio**: No solo discapacidad permanente, sino temporal, situacional, aging workforce
- Bake-in desde d√≠a 1 (no retrofit)

**Keyboard-First & Assistive Tech**:

- Full functionality via keyboard (power users + motor impairments)
- Visible focus indicators, logical tab order, shortcut keys
- **Screen readers**: ARIA labels, summary statistics read aloud
- **Ejemplo**: Dashboard widgets navegables v√≠a ARIA, stats spoken

**Inclusive Visual Design**:

- **Dark mode, high-contrast modes** out-of-box
- Color palettes color-blind friendly (texture/patterns en charts)
- Plain language, clear labels (no jargon ‚Üí non-native speakers, cognitive differences)

**Resultado**: Universal design = good design ‚Üí Overall satisfaction ‚Üë, competitive edge

**Conexi√≥n KERNEL**:

- **L√≠mite L3** (CORE/03 ¬ß3): WCAG como l√≠mite regulatorio
- **D2_Percepci√≥n O1**: Accessibility score como observable
- **E2_P√∫blico ¬ß6**: Gov-specific accessibility requirements (reference)

### ¬ß4.4 AI-Assisted UX

**Copilots Embedded**:

- LLM-powered assistants in-UI (chat, voice)
- **Ejemplo**: Microsoft 365 Copilot draft emails, summarize docs on command
- **Funciones**: Contextual help, domain Q&A, content generation, process guidance

**Predictive UX & Smart Automation**:

- Auto-suggest likely actions, pre-fill based on context
- **Ejemplo ERP**: "End-of-quarter ‚Üí Generate finance report now?"
- **Ejemplo CRM**: Auto-fill customer location from phone number

**Personalization ML**:

- Dashboards reorder to surface relevant metrics per user
- Learn visit patterns ‚Üí Bubble up frequent spaces
- **Hyper-personalization**: Role + habits adaptation (like consumer apps)
- **Ethics**: User control, transparency, opt-out

**Augmented Decision-Making**:

- AI crunch large datasets ‚Üí Present insights/recommendations in-UI
- **Ejemplo procurement**: Highlight best supplier (past performance, cost data)
- **Ejemplo HR**: Flag team burnout risk (workload, time-off patterns analysis)
- **UX challenge**: Transparent AI (confidence levels, reasoning shown)

**Conexi√≥n KERNEL**:

- **CORE/04 Delegaci√≥n ¬ß8**: Purpose 1 Assistant (M3 Enable mode expl√≠cito)
- **M3 Enable**: AI copilots enable user capabilities (contextual, bounded)
- **E8_Intelligent_Systems ¬ß5**: AI Orchestration patterns (reference, no duplicar)
- **P53 Orchestration Agent** (CORE/04 ¬ß8): Pattern AI agents

### ¬ß4.5 Multi-Device & Cross-Platform

**Responsive & Mobile-Friendly**:

- Responsive web design standard 2024 (desktop/tablet/mobile)
- Redesign workflows for mobile (not cramped desktop copy)
- **Resultado**: Employees accomplish key tasks on-the-go

**Companion Apps & Second-Screen**:

- **Ejemplo**: Google Meet Companion Mode (second device, no echo)
- Desktop deep exploration, mobile alerts + key metrics
- Tailor experience to device strengths (phone camera scan QR, PC bulk data analysis)

**Seamless Continuity**:

- Cloud sync, state preservation cross-device
- **Ejemplo**: Email draft phone ‚Üí Continue laptop right where left off
- Design systems ensure familiarity each device (no relearn)

**Offline Capability**:

- PWAs, local caching (poor connectivity resilience)
- **Ejemplo**: Sales rep CRM offline, data syncs later
- **Beneficio**: Productivity no halt when network fails

**Conexi√≥n**: D4_Operaci√≥n ¬ß6 Resilience patterns

### ¬ß4.6 Data Visualization

**Interactive Dashboards**:

- Click chart elements ‚Üí Filter/drill-down
- **Ejemplo**: Click sales bar ‚Üí See per-region details
- Adjust time ranges via sliders, hover granular tooltips

**Real-Time Data & Alerts**:

- Live operations metrics, IoT sensor data (seconds refresh)
- AI highlight anomalies: "This week output 15% below avg" (red flag)
- **Beneficio**: Transform dashboards ‚Üí Decision support tools

**Story-Focused Visuals**:

- Reduce clutter, clear purpose per chart
- Curated dashboards (cada chart tiene contexto: titles, captions, dynamic explanations)
- **Ejemplo**: Few key KPIs + trendlines + annotations (good/bad vs goal) + text blurb

**Data Democratization**:

- BI capabilities in everyday apps (no export to specialized tools)
- Self-service: drag-drop, natural language queries ("show sales by region as pie chart")
- **Resultado**: Insights no bottlenecked with analysts, data-savvy workforce

**Conexi√≥n**: A5_Medici√≥n ¬ß3 Dashboard structures (reference)

### ¬ß4.7 Design Systems

**Unified Component Library**:

- Centralized design system as mission-critical product
- Reusable components (buttons, icons, interactions) shared across apps
- **Beneficio**: Consistency (HR portal = B2B tool feel), accelerate dev, propagate updates

**Design Tokens & Theming**:

- Variables for colors, spacing, typography (design attributes)
- **Enable**: Multi-brand support (white-label SaaS), light/dark mode swap minimal effort
- **W3C Design Tokens spec**: Standardizing token formats (Figma ‚Üî code sync)

**Dev Workflow Integration**:

- Living style libraries (Storybook, Figma integration)
- **Source of truth**: Coded component library (design ‚â° reality, no drift)
- Governance boards: Evaluate new components, manage updates, usage metrics

**Scalable & Future-Proof**:

- Enterprise software lives decades ‚Üí Update system (not rebuild from scratch)
- **Extensibility**: Bake-in i18n, accessibility, multi-device from start
- **Resultado**: Large app ecosystems agile, resilient to change

**Conexi√≥n KERNEL**:

- **CORE/06 Capacidades ¬ß4**: Design system como capacidad habilitadora C7
- **D1_Arquitectura**: Component architecture patterns
- **A4_Implementaci√≥n ¬ß3**: Design system governance

---

## ¬ß5. DEVOPS & PLATFORM ENGINEERING

### CI/CD Pipelines

**Automated Build, Test, Deploy**:

- **Tools**: GitHub Actions, GitLab CI, Jenkins, CircleCI
- **Pipeline stages**: Build ‚Üí Unit tests ‚Üí Integration tests ‚Üí Security scans ‚Üí Deploy
- **Principio**: Every commit triggers pipeline (fail fast)

**Testing Pyramid**:

- **Base s√≥lida**: Unit tests (70%)
- **Complemento**: Integration tests (20%)
- **Capa fina**: E2E tests (10%) - Cypress, Playwright

**Contract Testing**:

- Pact para microservicios (compatibility sin entorno integraci√≥n completo)
- Valida consumer-provider contracts aisladamente

**Performance Testing**:

- k6, JMeter para simular carga
- Validate NFRs pre-producci√≥n (latency p95, throughput)

**Conexi√≥n KERNEL**:

- **D4_Operaci√≥n ¬ß4**: CI/CD detallado (reference, no duplicar)
- **Flujo F2** (CORE/02): Automated flow como primitivo
- **P23 Feature Flags** (APLICACION/A1): Decouple deploy/release

### Infrastructure-as-Code

**Declarative Infra**:

- **Tools**: Terraform (cloud-agnostic), Pulumi (code-native), CloudFormation (AWS)
- **Beneficio**: Infra versionada Git, reproducible, auditable

**Containerization & Orchestration**:

- **Docker**: Package apps + dependencies (consistency dev ‚Üí prod)
- **Kubernetes**: Orchestration standard de-facto (scheduling, scaling, self-healing)

**Deployment Strategies**:

- **Blue-Green**: Two identical envs, instant switch, instant rollback
- **Canary**: Gradual rollout (5% ‚Üí 50% ‚Üí 100%), monitor metrics, auto-rollback
- **Rolling**: Update instances incrementally (zero downtime)

**Conexi√≥n**: P24 Blue-Green Deployment (APLICACION/A1)

### Observability (3 Pillars)

**No es solo monitoreo** ‚Üí Es capacidad de entender internal states desde outputs externos.

**Pilar 1: Logs**:

- **Structured logs** (JSON) para procesamiento autom√°tico
- **Tools**: ELK Stack (Elasticsearch, Logstash, Kibana), Loki + Grafana
- **Campos est√°ndar**: timestamp, level, service, trace_id, message, context

**Pilar 2: Metrics**:

- **Time-series** para dashboards y alertas
- **Tools**: Prometheus (scraping, storage), Grafana (visualization)
- **Golden signals**: Latency, Traffic, Errors, Saturation (Google SRE)

**Pilar 3: Traces**:

- **Distributed tracing** para debugging bottlenecks en sistemas complejos
- **Tools**: Jaeger, Zipkin, OpenTelemetry (vendor-agnostic standard)
- **Beneficio**: End-to-end request flow visibility (microservices)

**Unified Observability**:

- **OpenTelemetry**: Single SDK for logs/metrics/traces (vendor-neutral)
- **Correlation**: trace_id links logs + metrics + spans (holistic debugging)

**Conexi√≥n KERNEL**:

- **D2_Percepci√≥n ¬ß2**: Observables t√©cnicos (O2-O4)
- **A5_Medici√≥n ¬ß5**: DORA metrics (reference)
- **CORE/05 Smartness ¬ß4**: Observability como smartness habilitador

### Feature Flags

**Decouple Deploy ‚Üî Release**:

- Deploy c√≥digo production (flag OFF) ‚Üí Enable feature runtime (flag ON)
- **Beneficio**: Canary releases, A/B testing, instant kill switch

**Tools**: LaunchDarkly, Unleash, ConfigCat, custom (Redis-backed)

**Conexi√≥n**: P23 Feature Flags (APLICACION/A1)

---

## ¬ß6. SECURITY SHIFT-LEFT

### Principio

**Integrar seguridad desde inicio** del ciclo de vida (no post-hoc).

### Autenticaci√≥n & Autorizaci√≥n

**Autenticaci√≥n**:

- **Standards**: OAuth 2.1 / OIDC (industry standard)
- **JWT**: Stateless APIs (token-based, no server sessions)
- **MFA**: Multi-factor (algo tienes + algo sabes + algo eres)

**Autorizaci√≥n**:

- **RBAC** (Role-Based): Permisos por roles (simple, mayor√≠a casos)
- **ABAC** (Attribute-Based): Permisos granulares por atributos (contexto, tiempo, recurso)
- **Principio**: Least privilege (m√≠nimo necesario)

**Conexi√≥n KERNEL**:

- **Actor A4** (CORE/03 ¬ß4): Roles y permisos como actor capabilities
- **L√≠mite L4** (CORE/03 ¬ß5): Authorization policies como l√≠mites de acceso

### OWASP Top 10 & Automated Detection

**SAST** (Static Application Security Testing):

- Analiza c√≥digo fuente en CI pipeline (pre-commit hooks, PR gates)
- Tools: SonarQube, Checkmarx, Semgrep

**DAST** (Dynamic Application Security Testing):

- Escanea app running en staging/pre-prod
- Tools: OWASP ZAP, Burp Suite

**SCA** (Software Composition Analysis):

- Analiza dependencias terceros (vulnerabilities conocidas)
- Tools: Dependabot, Snyk, Trivy

**Principio**: Automatizar detecci√≥n (no manual reviews post-deploy)

### Secrets Management

**Vault Centralizado**:

- **Tools**: HashiCorp Vault, AWS Secrets Manager, GCP Secret Manager, Azure Key Vault
- **Principio absoluto**: **NEVER hardcode secrets** (c√≥digo, env vars Git, configs)

**Just-In-Time Credentials**:

- Apps/bots autentican ‚Üí Obtain credentials runtime (time-bounded tokens)
- **Rotation autom√°tica**: Secrets rotan peri√≥dicamente (reduce blast radius)

**Conexi√≥n**: D4_Operaci√≥n ¬ß8 Security practices

---

## ¬ß7. NFRs Y SLOs

### Non-Functional Requirements

**Performance**:

- **Latency**: p50, p95, p99 targets (ms)
- **Throughput**: Requests/sec, transactions/sec
- **Example**: API p95 latency <200ms, throughput >1000 req/s

**Availability**:

- **Uptime SLO**: 99.9% (8.76h downtime/a√±o), 99.99% (52.6min/a√±o)
- **Error budget**: (1 - SLO) √ó time_window ‚Üí Budget errors/downtime permitidos

**Scalability**:

- Horizontal scaling capacity (add instances, not vertical resize)
- Auto-scaling triggers (CPU >70%, queue length >100)

### Architecture Decision Records (ADRs)

**Prop√≥sito**: Documentar decisiones arquitect√≥nicas clave y justificaciones para futuro.

**Estructura ADR**:

1. **Context**: Problem/situation
2. **Decision**: What we decided
3. **Consequences**: Positive/negative outcomes expected
4. **Alternatives considered**: Why rejected
5. **Status**: Proposed, Accepted, Deprecated, Superseded

**Storage**: Git-versioned (markdown en `/docs/adr/`)

**Template**: T13_ADR (REFERENCIA/R6_Templates) - existente v1.4

### C4 Diagrams

**Architecture as Code** (4 niveles abstracci√≥n):

1. **Context**: System ‚Üî Users/External systems
2. **Containers**: High-level tech stack (apps, databases, message buses)
3. **Components**: Internal structure containers
4. **Code**: Classes/interfaces (opcional, low-level)

**Tools**: PlantUML, Structurizr, Mermaid

---

## ¬ß8. CONEXI√ìN KERNEL

### Primitivos Especializados

| Primitivo KERNEL | Manifestaci√≥n E7 | Ejemplo Concreto |
|:---|:---|:---|
| **Recurso** | Applications, tech stack, infrastructure, platform | API Gateway (R3), PostgreSQL cluster (R3), K8s cluster (R3) |
| **Flujo** | CI/CD pipelines, user workflows, data flows | GitLab CI pipeline (F2 Automated), User checkout flow (F1 Manual) |
| **Actor** | Developers, SRE, DevOps Eng, Platform Eng, End-users | DevOps Engineer (A3 Specialized), End-user (A1 Principal) |
| **L√≠mite** | NFRs, SLOs, API contracts, regulatory, error budgets | API p95 <200ms (L1 Performance), WCAG AA (L3 Regulatory) |

### Dominios KERNEL Extendidos

**D1_Arquitectura**:

- Stack patterns (¬ß2 E7) extend D1 architecture thinking
- Conway's Law aplicado (D1 ¬ß1 P4)
- ADRs como architectural decisions traceable

**D2_Percepci√≥n**:

- Tech observables: DORA metrics (deploy freq, lead time, MTTR, change failure rate)
- Uptime %, error rate %, latency p95
- **Extension**: D2 + ¬ß8 Tech Observables (Week 6)

**D3_Decisi√≥n**:

- Stack selection framework (¬ß3 decision framework)
- Trade-offs analysis explicit (tabla ¬ß2)
- Build vs Buy decisions

**D4_Operaci√≥n**:

- CI/CD practices (D4 ¬ß4 existing, reference)
- Deployment strategies (blue-green, canary, rolling)
- SRE on-call rotations, incident response

### Delegaci√≥n M1-M6 en UX Layer

| Modo Delegaci√≥n | Manifestaci√≥n UX/Tech | Ejemplo E7 |
|:---|:---|:---|
| **M1 Monitor** | Dashboards pasivos, alertas | Grafana dashboard operations (human monitors) |
| **M2 Inform** | Chatbots info-only, knowledge bases | FAQ bot (inform, no execute) |
| **M3 Enable** | AI copilots, predictive UX, auto-suggest | Microsoft Copilot draft email (enable user, user approves) |
| **M4 Control** | Automated testing gates, quality checks | CI pipeline auto-reject PR (fails tests, human fixes) |
| **M5 Co-produce** | AI-assisted coding, pair programming | GitHub Copilot code suggestions (human edits, approves) |
| **M6 Execute** | Automated deployments, self-healing infra | K8s auto-restart failed pods, auto-scale (bounded, monitored) |

**Conexi√≥n**: CORE/04 Delegaci√≥n ¬ß3-¬ß8 (matriz completa)

---

## ¬ß9. CASOS DE USO

### Caso 1: Startup Monolito ‚Üí Microservicios (Migration)

**Contexto**:

- Startup SaaS B2B, 10 engineers ‚Üí 50 engineers en 3 a√±os
- Monolito Ruby on Rails (150K LOC)
- **Pain points**: Deploy freq 1 cada 3 semanas (bottleneck), merge conflicts daily, testing suite 45 min (slow feedback)

**Approach (Pattern P06 Inverse Conway)**:

1. **A√±o 1**: Mantener monolito, agregar **modularizaci√≥n interna** (bounded contexts DDD)
   - 3 contexts: Authentication, Billing, Analytics
   - Refactor internal APIs claras entre contexts
2. **A√±o 2**: Split teams por context (3 teams √ó 10-15 eng)
   - Architecture follows org (Conway's Law)
3. **A√±o 3**: Extract 2 microservicios cr√≠ticos
   - **Billing** (alta volatilidad reglas negocio, deploy frecuente necesario)
   - **Authentication** (security isolation, independent scaling)
   - Mantener Analytics en monolito (stable, bajo cambio)

**Stack**:

- Monolito: Ruby on Rails (legacy)
- Microservicios: Node.js (NestJS) - team preference, faster iteration
- Infra: K8s (GKE), PostgreSQL (cada microservicio su DB), Redis (cache shared), Kafka (event bus)
- Observability: OpenTelemetry + Jaeger + Prometheus + Grafana

**M√©tricas**:

- **Deploy frequency**: 1 cada 3 semanas ‚Üí 5/d√≠a (DORA Elite)
- **Lead time**: 15 d√≠as ‚Üí 2 d√≠as
- **MTTR**: 4 horas ‚Üí 45 min
- **Change failure rate**: 15% ‚Üí 8%

**Timeline**: 18 meses (modularizaci√≥n 6m, split teams 6m, extract 6m)

**Conexi√≥n KERNEL**:

- **P06 Inverse Conway** (A1): Pattern aplicado expl√≠citamente
- **D4 ¬ß4 CI/CD**: Execution practices
- **A5 ¬ß5 DORA**: Metrics framework

### Caso 2: Enterprise Multi-Product Design System

**Contexto**:

- Enterprise 5 productos B2B SaaS
- **Pain**: Inconsistencia UX (cada producto UI diferente), Dev velocity bajo (reinvent components cada vez)

**Soluci√≥n** (¬ß4.7 Design System):

1. **Audit**: Inventario components 5 productos ‚Üí 347 componentes, 89% duplicados
2. **Design**: Unified component library (42 core components)
3. **Governance**: Design System team (3 designers, 2 FE engineers)
4. **Adoption**: Migrate producto por producto (6 meses cada)

**Stack**:

- Component library: React + TypeScript + Storybook
- Design tokens: JSON format (W3C spec)
- Distribution: NPM private registry

**M√©tricas**:

- **Dev velocity**: +40% (time-to-market new features)
- **Consistency score**: 35% ‚Üí 95% (automated UI tests)
- **Component reuse**: 12% ‚Üí 78%
- **Design-dev handoff time**: 5 d√≠as ‚Üí 1 d√≠a

**Timeline**: 24 meses (design 6m, build 6m, adoption 12m)

### Caso 3: SaaS Multi-Tenant Architecture

**Contexto**: Single-tenant app ‚Üí Multi-tenant migration (scale 50 customers ‚Üí 5000)

**Patterns**:

- **DB per tenant** (isolation m√°xima, compliance)
- **Feature flags per tenant** (gradual rollout, A/B testing)
- **Tenant-aware observability** (metrics per tenant)

**Resultado**:

- **Onboarding**: 2 semanas ‚Üí 2 horas (automated provisioning)
- **Cost per tenant**: -60% (shared infra)
- **Compliance**: Tenant isolation garantizada (GDPR, SOX)

**Conexi√≥n**: P23 Feature Flags, D4 ¬ß7 Multi-tenancy patterns

---

## ¬ß10. ANTIPATRONES

### AP_TECH1: Premature Microservices

**S√≠ntoma**: Startup 5 engineers comienza con 15 microservicios sin justificar.

**Causa**: Hype-driven architecture, no pain real con monolito.

**Consecuencia**:

- Complejidad operacional >10√ó (service discovery, distributed tracing, eventual consistency)
- Dev velocity -70% (setup overhead, debugging cross-service)
- Team cognitive load insostenible

**Fix**: Start monolito modular ‚Üí Extract microservicios cuando **dolor > complejidad** (¬ß2 principio).

**Prevention**: Aplicar **P54 Piecemeal Growth** (APLICACION/A1) - grow incrementally.

**Severidad**: üü° Importante (recoverable, pero costoso)

### AP_TECH2: Frontend-Backend Coupling

**S√≠ntoma**: Frontend directamente acopla a backend DB schemas/internal APIs.

**Causa**: No BFF (Backend-for-Frontend) layer, no API contracts estables.

**Consecuencia**:

- Deploy dependencies (frontend requiere backend deploy simult√°neo)
- Violates team autonomy (frontend bloqueado por backend changes)
- API versioning imposible (breaking changes cada deploy)

**Fix**:

- Introducir **API Gateway** con contracts estables (OpenAPI specs)
- BFF layer para cada client type (web, mobile, partner APIs)
- **Semantic versioning** APIs (major.minor.patch)

**Prevention**: Contract-first design (API spec antes implementation).

**Severidad**: üü° Importante

### AP_TECH3: Big Design Up Front (BDUF)

**S√≠ntoma**: 6 meses dise√±o arquitect√≥nico detallado antes de escribir c√≥digo.

**Causa**: Waterfall mindset, fear of refactoring, architecture astronauts.

**Consecuencia**:

- Requirements drift (realidad ‚â† dise√±o cuando finalmente builds)
- Sunk cost fallacy (inversi√≥n dise√±o ‚Üí resist change)
- Time-to-market delay massive

**Fix**: **P54 Piecemeal Growth + P55 Walking Skeleton** (APLICACION/A1 v1.4):

- Walking Skeleton primero (end-to-end m√≠nimo funcional)
- Iterate con feedback real
- **P56 Continuous Refactoring** (mantener calidad)

**Mitigaci√≥n**: Ya mitigado por P54-P56 v1.4 refactorizaci√≥n.

**Severidad**: üü° Importante (menos com√∫n 2024, pero persiste en orgs tradicionales)

**Conexi√≥n KERNEL**:

- **APLICACION/A2**: Antipatrones base (cross-reference)
- **P54-P56**: Patterns desarrollo que previenen BDUF

---

## ¬ß11. PLANTILLAS RELACIONADAS

### Plantillas T√©cnicas

**T19_App_Inventory** (REFERENCIA/R6_Templates, nuevo v2.0):

- Metadatos de la aplicaci√≥n (stack, observabilidad, NFRs, salud)
- Trazabilidad KERNEL (primitivos, dominios, delegaci√≥n)
- Puntuaci√≥n de deuda t√©cnica, instant√°nea de m√©tricas DORA

**T13_ADR** (existente v1.4):

- Registro de Decisi√≥n de Arquitectura
- Referencia para decisiones de stack y arquitectura

### Plantillas de Contratos

**T15_Contrato_Datos** (nuevo v2.0):

- Contratos de datos para aplicaciones intensivas en datos (referencia E8 ¬ß3)

**T20_Data_Product_Spec** (nuevo v2.0):

- Para aplicaciones que son productos de datos (referencia E8 ¬ß4)

**Conexi√≥n**: E8_Intelligent_Systems para contratos detallados (no duplicar aqu√≠)

---

## ¬ß12. M√âTRICAS

### M√©tricas DORA

**4 M√©tricas Clave** (investigaci√≥n DORA de Google, est√°ndar de la industria):

| M√©trica | √âlite | Alto | Medio | Bajo |
|:---|:---|:---|:---|:---|
| **Frecuencia de Despliegue** | Bajo demanda (>1/d√≠a) | 1/semana - 1/mes | 1/mes - 6/mes | <1 cada 6 meses |
| **Tiempo de Entrega para Cambios** | <1 d√≠a | 1 d√≠a - 1 semana | 1 semana - 1 mes | 1-6 meses |
| **Tiempo de Restauraci√≥n (MTTR)** | <1 hora | <1 d√≠a | 1 d√≠a - 1 semana | >1 semana |
| **Tasa de Fallos en Cambios** | 0-15% | 16-30% | 31-45% | 46-60% |

**Conexi√≥n KERNEL**:

- **A5_Medici√≥n ¬ß5**: M√©tricas DORA detalladas (referencia, no duplicar)
- **D2_Percepci√≥n**: DORA como observables t√©cnicos

### Puntuaci√≥n de Salud T√©cnica

**Formula**:

```
Puntuacion_Salud_Tecnica = (Salud_Infraestructura + Salud_Seguridad + Salud_Observabilidad + Madurez_DevOps) / 4
```

**Componentes** (cada uno de 0 a 100):

1. **Salud_Infraestructura**:
   - % de tiempo de actividad (peso 0.4)
   - Efectividad del autoescalado (0.3)
   - Utilizaci√≥n √≥ptima de recursos (0.3)

2. **Salud_Seguridad**:
   - Vulnerabilidades cr√≠ticas = 0 (0.5)
   - Cumplimiento de la gesti√≥n de secretos (0.3)
   - % de adopci√≥n de MFA (0.2)

3. **Salud_Observabilidad**:
   - % de cobertura de logs/m√©tricas/trazas (0.4)
   - Cobertura de alertas en rutas cr√≠ticas (0.3)
   - Tiempo medio de detecci√≥n (MTTD) <5min (0.3)

4. **Madurez_DevOps**:
   - Puntuaci√≥n compuesta de DORA (0.6)
   - % de cobertura de IaC (0.2)
   - Cobertura de pruebas automatizadas (0.2)

**Benchmarks**:

- **>85**: Excellent (world-class)
- **70-85**: Good (industry standard)
- **<70**: Needs attention

### Tech Debt Score

**Reference**: D4_Operaci√≥n ¬ß5 Tech Debt detallado (no duplicar)

**Integraci√≥n**: TH_Score complementa H_Score (CORE/05) para dimensi√≥n tech.

**Conexi√≥n**: A5_Medici√≥n ¬ß10 Tech Metrics (extension v2.0 Week 7)

---

## REFERENCIAS CRUZADAS

### CORE

- **CORE/01 Recurso**: Stack como recurso habilitador
- **CORE/02 Flujo**: CI/CD como flujo automatizado
- **CORE/03 Actor**: Developers, SRE como actores especializados
- **CORE/03 L√≠mite**: NFRs, SLOs como l√≠mites operacionales
- **CORE/04 Delegaci√≥n ¬ß8**: Purpose 1 Assistant (AI copilots UX)
- **CORE/05 Smartness**: Observability como smartness habilitador

### DOMINIOS

- **D1_Arquitectura ¬ß1 P4**: Conway's Law awareness
- **D1 ¬ß14** (extension v2.0): Tech Stack Patterns detallado
- **D2_Percepci√≥n ¬ß2**: Observables base O1-O11
- **D2 ¬ß8** (extension v2.0): Tech Observables OT1-OT3
- **D3_Decisi√≥n ¬ß3**: Decision modes arquitect√≥nicos
- **D4_Operaci√≥n ¬ß4**: CI/CD detallado (primary reference)
- **D4 ¬ß5**: Tech debt management
- **D4 ¬ß8**: Security practices

### APLICACION

- **A1_Patrones**:
  - P06 Inverse Conway's Law
  - P23 Feature Flags
  - P24 Blue-Green Deployment
  - P54 Piecemeal Growth
  - P55 Walking Skeleton
  - P56 Continuous Refactoring
- **A2_Antipatrones**: AP_TECH1-3 cross-reference
- **A3_Diagn√≥stico ¬ß4**: UX friction assessment
- **A4_Implementaci√≥n ¬ß3**: Design system governance
- **A5_Medici√≥n ¬ß5**: DORA metrics framework (primary reference)

### DOMINIOS_ESPECIALIZADOS

- **E8_Intelligent_Systems**: Data/AI/Process/Knowledge (orthogonal, minimal overlap infra K8s/OpenTelemetry)
- **E2_P√∫blico ¬ß6**: Gov UX requirements (sector-specific)
