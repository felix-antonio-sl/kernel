# A4_Implementacion

**Versión:** 2.0.0 | **Estado:** Revisión | **Audiencia:** Implementadores, PMO, Change Leaders

---

## §0. TRIAGE Y ENRUTAMIENTO

### 0.1 Propósito

```yaml
Función: Routing decision basado en organizational health
Input: H_Score + Observables críticos
Output: Transformation path + Protocol reference
Principio: Diagnóstico precede prescripción
```

---

### 0.2 Decision Matrix

```yaml
Estado_Organizacional:
  
  CRISIS_EXISTENCIAL:
    Condición: H_Score < 15
    Indicadores:
      - Múltiples observables < 15
      - Cash runway < 7 días
      - Service collapse inminente
    Path: → CORE/08_Crisis_Management.md
    Objetivo: Supervivencia (24-72h horizon)
    
  CRISIS_ESTABILIZACIÓN:
    Condición: H_Score 15-45
    Indicadores:
      - Observables críticos 15-30
      - Cash runway 7-90 días
      - Churn >20% o talent exodus >20%
    Path: → CORE/08 + A3_Diagnostico (secuencial)
    Objetivo: Detener deterioro → Root cause
    
  MEJORA_ESTRUCTURADA:
    Condición: H_Score 45-60
    Indicadores:
      - Sin crisis activa
      - Readiness variable (evaluar 5 dimensiones)
    Path: → §0.3 Readiness Assessment
    Objetivo: Transformación sostenible
    
  OPTIMIZACIÓN_CONTINUA:
    Condición: H_Score > 60
    Indicadores:
      - Organización saludable
      - Capacidad de absorción alta
    Path: → §1-§7 (cadencia normal)
    Objetivo: Excelencia incremental
```

---

### 0.3 Readiness Assessment (H_Score 45-60)

```yaml
Dimensiones_Críticas:
  
  D1_Alineación_Liderazgo:
    Pregunta: "¿Executive team unificado en necesidad y approach?"
    Escala:
      5: Consenso total, sponsor comprometido
      3: Mayoría alineada, escépticos manejables
      1: Fragmentación, sin coalición viable
    Peso: Crítico (sin esto, failure rate >80%)
  
  D2_Urgencia_Legitimada:
    Pregunta: "¿Existe burning platform o window of opportunity?"
    Escala:
      5: Amenaza/oportunidad clara, plazo definido
      3: Caso deseable pero no imperativo
      1: Sin urgencia, status quo aceptable
    Peso: Alto
  
  D3_Recursos_Comprometidos:
    Pregunta: "¿Tiempo, presupuesto y personas allocated?"
    Escala:
      5: Full allocation (15-25% capacity org)
      3: Recursos disponibles pero constrained
      1: Sin budget, capacidad límite
    Peso: Crítico
  
  D4_Capacidad_Técnica:
    Pregunta: "¿Skills para diseñar e implementar?"
    Escala:
      5: In-house capability o budget external
      3: Upskilling necesario pero viable
      1: No capability, no path to acquire
    Peso: Medio
  
  D5_Bandwidth_Organizacional:
    Pregunta: "¿Puede absorber change mientras opera?"
    Escala:
      5: Utilización <80%, slack disponible
      3: Tight (80-90%) pero manejable
      1: Overload (>95%), sin margen
    Peso: Alto

Decision_Logic:
  
  IF ALL(D1-D5) >= 4:
    → GO_FULL: Transformación completa (§1-§7)
  
  IF MOST(D1-D5) >= 3:
    → GO_PILOT: Phased approach
    → Start: 1-2 teams, 3 meses
    → Learn: Adjust antes scaling
  
  IF ANY(D1-D5) < 3:
    → BUILD_READINESS:
    → Address gaps específicos
    → Re-assess en 3-6 meses
  
  IF ANY(D1-D5) = 1:
    → DELAY:
    → Forcing transformation = alta probabilidad failure
    → Fix prerequisites primero
```

---

### 0.4 Anti-Patterns Triage

```yaml
AP32_Forzar_Transformación_Sin_Readiness:
  Síntoma: Iniciar con readiness score < 3
  Causa_Raíz: Executive impatience, ignoring prerequisites
  Consecuencia: 70% failure rate, credibility loss
  Remediación: Build readiness primero (3-6 meses investment)
  
AP33_Transformar_Durante_Crisis:
  Síntoma: Major reorg con H_Score < 45
  Causa_Raíz: "Never waste crisis" mal interpretado
  Consecuencia: Crisis deepens, transformation aborts
  Remediación: Stabilize FIRST (P52) → Transform AFTER (H>45)
  Referencia: CORE/08_Crisis_Management.md §5
```

---

### 0.5 Exit Criteria por Path

```yaml
Crisis_Existencial → Crisis_Estabilización:
  Criterio: H_Score > 30 sostenido 2+ semanas
  Validación: No regression observables críticos
  
Crisis_Estabilización → Mejora_Estructurada:
  Criterio: H_Score > 45 sostenido 3 meses
  Validación: Root causes identificadas, no bleeding active
  
Mejora_Estructurada → Ejecución_Normal:
  Criterio: Readiness score >= 3 en todas dimensiones
  Validación: Coalition formada, budget secured
```

## §1. ARQUITECTURA DE TRANSFORMACIÓN

### 1.1 Invariantes del Proceso

```yaml
Estructura_Mínima:
  Fases: 6 (Diagnóstico → Diseño → Preparación → Piloto → Escalamiento → Sostenibilidad)
  Roles: 3 (Sponsor, Coalition, PMO)
  Gates: 9 (validation points críticos)
  
Principio_Ortogonalidad:
  Separación:
    - Qué (outcomes esperados)
    - Cómo (métodos y técnicas)
    - Cuándo (secuencia y timing)
    - Quién (roles y responsabilidades)
  
Trazabilidad_Causal:
  Cadena: Antipatrón → Root Cause → Patrón → Acción → Métrica → Outcome
  Bidireccional: Forward (predict) + Backward (diagnose)
```

---

### 1.2 Modelo de Fases

```yaml
Fase_Template_Uniforme:
  
  Input: Deliverables fase anterior + Gates aprobados
  
  Estructura:
    - Objetivo (outcome esperado)
    - Actividades (qué hacer, secuencia)
    - Roles (quién responsable)
    - Deliverables (artifacts producidos)
    - Gates (criterios exit)
    - Métricas (leading + lagging indicators)
  
  Output: Deliverables validados → Input fase siguiente
  
  Governance: Review semanal (PMO) + Gate review (Coalition/Sponsor)

Duración_Típica:
  Org_100-500_personas:
    Total: 12-24 meses
    Breakdown:
      - Diagnóstico: 3-4 semanas
      - Diseño: 4-6 semanas
      - Preparación: 4-8 semanas
      - Piloto: 8-12 semanas
      - Escalamiento: 12-24 semanas
      - Sostenibilidad: Continuo (18-24 meses handoff)
  
  Scaling_Factor:
    <100_personas: -30% tiempo
    500-1000: +50% tiempo
    >1000: +100-150% tiempo + sub-waves
```

---

### 1.3 Modelo de Roles

```yaml
R1_Sponsor_Ejecutivo:
  Perfil: C-level con authority budget y org design
  Responsabilidades:
    - Aprobar investment (budget, headcount)
    - Remover blockers estructurales
    - Comunicar urgency y legitimacy
    - Decisiones escalation Level 4
  Commitment: 2-4h/semana
  
R2_Guiding_Coalition:
  Perfil: 8-12 personas (power + expertise + credibility)
  Composición:
    - 3-4 execs (VPs)
    - 3-4 domain experts (architects, product leads)
    - 2-3 influencers (informal power)
  Responsabilidades:
    - Diseñar target state
    - Validar gates críticos
    - Champion cambio en sus áreas
    - Decisiones escalation Level 3
  Commitment: 4-8h/semana durante Fases 2-5
  
R3_Transformation_PMO:
  Perfil: 2-3 personas full-time (project management + change expertise)
  Responsabilidades:
    - Ejecutar playbook día a día
    - Facilitar ceremonies y workshops
    - Tracking métricas y risks
    - Comunicación operacional
    - Support teams durante transition
  Commitment: 100% dedicated Fases 2-5, 70% Fase 6 hasta handoff
  
R4_Pilot_Teams:
  Perfil: 2 teams, 5-9 personas c/u, high-performing + representative
  Responsabilidades:
    - Validar target state (Fase 4)
    - Generar learnings para scale
    - Peer coaching en Fase 5
  Commitment: 10-15% overhead durante pilot
  
R5_Line_Managers:
  Perfil: Todos los managers org (functional + product)
  Responsabilidades:
    - Comunicar cascade en sus equipos
    - 1:1s empathy durante transition
    - Identificar resistance y escalate
    - Sustain cambios post-PMO
  Commitment: 2-3h/semana extra durante Fases 4-5
```

---

### 1.4 Modelo de Gobernanza

```yaml
Ceremonies_Operacionales:
  
  Daily_Standup_PMO:
    Frecuencia: Diaria durante Fases 4-5
    Duración: 15 min
    Participantes: PMO team
    Objetivo: Coordinación táctica
  
  Weekly_Status_Review:
    Frecuencia: Semanal durante todas fases
    Duración: 60 min
    Participantes: PMO + Sponsor
    Agenda:
      - Progress vs plan (15 min)
      - Blockers y risks (20 min)
      - Decisions needed (15 min)
      - Next week plan (10 min)
  
  Bi-Weekly_Coalition_Review:
    Frecuencia: Quincenal durante Fases 2-5
    Duración: 90 min
    Participantes: Coalition + PMO
    Agenda:
      - Métricas dashboard (20 min)
      - Deep-dive 1 tema crítico (40 min)
      - Gate reviews si aplica (20 min)
      - Adjustments roadmap (10 min)
  
  Gate_Reviews:
    Frecuencia: 9 momentos específicos (ver §1.5)
    Duración: 60-120 min según criticality
    Participantes: Sponsor + Coalition + PMO
    Output: Go / No-Go / Conditional (con remediation plan)

Artifacts_Tracking:
  
  Transformation_Roadmap:
    Update: Semanal
    Owner: PMO
    Consumers: Toda org (visibility)
  
  Risk_Register:
    Update: Semanal
    Owner: PMO
    Review: Coalition bi-weekly
  
  Metrics_Dashboard:
    Update: Semanal (leading) + Mensual (lagging)
    Owner: PMO (collect) + Data team (automate)
    Review: Coalition bi-weekly
  
  Decision_Log:
    Update: Cada decisión significativa
    Owner: PMO (record) + Coalition (approve)
    Format: Contexto + Opciones + Decisión + Rationale + Owner
```

---

### 1.5 Sistema de Gates

```yaml
Gate_Architecture:
  
  Propósito: Validación stage antes proceder (fail-fast)
  Principio: Objective criteria + Evidence-based
  
  Gate_Types:
    Type_1_Access: "¿Tenemos prerequisites necesarios?"
    Type_2_Quality: "¿Deliverables cumplen standard?"
    Type_3_Readiness: "¿Org preparada para next stage?"

Gates_Inventory:
  
  G1_Diagnóstico_Acceso:
    Fase: 1 (Diagnóstico)
    Timing: Semana 1
    Criterio: Acceso sistemas + Calendarios entrevistas confirmados
    Evidencia: Access grants + 30 entrevistas scheduled
    Decisión: GO → Continue | NO-GO → Escalate sponsor (delay 1-2 sem)
  
  G2_Datos_Suficientes:
    Fase: 1 (Diagnóstico)
    Timing: Semana 3
    Criterio: 8+ de 11 observables con data quality >80%
    Evidencia: Data collection log + H_Score calculable
    Decisión: GO → Calculate H_Score | NO-GO → Extend collection
  
  G3_Budget_Aprobado:
    Fase: 1 → 2
    Timing: Final Fase 1
    Criterio: C-level aprueba investment Fases 2-6
    Evidencia: Budget approval formal + Sponsor commitment
    Decisión: GO → Fase 2 | NO-GO → Pause (no funding = no proceed)
  
  G4_Target_State_Validado:
    Fase: 2 (Diseño)
    Timing: Semana 4
    Criterio: 80%+ stakeholders "design hace sentido"
    Evidencia: 10 validation interviews + Feedback incorporated
    Decisión: GO → Continuar | NO-GO → Adjust design, re-validate
  
  G5_Coalition_Formada:
    Fase: 2 → 3
    Timing: Final Fase 2
    Criterio: 8-12 personas committed (power + expertise + credibility)
    Evidencia: Coalition charter signed + Roles accepted
    Decisión: GO → Fase 3 | NO-GO → STOP (sin coalición, failure rate >90%)
  
  G6_Communication_Reach:
    Fase: 3 (Preparación)
    Timing: Semana 2
    Criterio: >85% org aware of transformation
    Evidencia: Survey results + Attendance town hall
    Decisión: GO → Training | NO-GO → Extended communication
  
  G7_Pilot_Teams_Ready:
    Fase: 3 → 4
    Timing: Final Fase 3
    Criterio: 2 teams volunteer + trained + systems access
    Evidencia: Readiness checklist 100% + Team charters signed
    Decisión: GO → Pilot | NO-GO → Delay (better preparation needed)
  
  G8_Pilot_Success:
    Fase: 4 → 5
    Timing: Final Fase 4 (semana 12)
    Criterio: Metrics improvement >20% + Team satisfaction >75/100
    Evidencia: Pilot report + Data dashboard + Team recommendation
    Decisión: GO → Scale | MIXED → Extend 4 sem | FAIL → Deep-dive pause
  
  G9_Scale_Validated:
    Fase: 5 (Escalamiento)
    Timing: Per wave (cada 6 semanas)
    Criterio: >70% teams wave actual met success criteria
    Evidencia: Wave metrics + Issues log + Retrospectiva
    Decisión: GO → Next wave | NO-GO → Pause, diagnose issues

Gate_Review_Protocol:
  
  1. Pre-work: PMO prepara evidence pack (envío 48h antes)
  2. Review: Coalition + Sponsor evalúa (60-120 min meeting)
  3. Decisión: Go / No-Go / Conditional (documented)
  4. Si Conditional: Remediation plan (owner + deadline)
  5. Re-review: Si conditional, re-check deadline
```

## §2. FASE 1: DIAGNÓSTICO

**Referencia Completa:** `APLICACION/A3_Diagnostico.md`

### 2.1 Objetivo

```yaml
Input: H_Score range conocido (de §0 triage)
Output: Root cause analysis + Top 5 recomendaciones priorizadas
Duración: 3-4 semanas
```

---

### 2.2 Actividades

```yaml
Semana_1_Setup:
  ☐ Kick-off meeting (Sponsor + Coalition + PMO)
  ☐ Accesos sistemas obtenidos (logs, metrics, repos)
  ☐ Entrevistas scheduled (30 personas target)
  ☐ Primeras 10 entrevistas realizadas
  
Semana_2_Data_Collection:
  ☐ 20 entrevistas restantes completadas
  ☐ Métricas 11 observables recolectadas (O1-O8, IN1-IN3)
  ☐ Análisis preliminar patterns/anti-patterns
  
Semana_3_Analysis:
  ☐ H_Score calculado con confidence intervals
  ☐ Antipatrones identificados (AP01-AP35)
  ☐ Gap analysis patrones (P01-P53)
  ☐ Root cause mapping (antipatrones → causas estructurales)
  
Semana_4_Synthesis:
  ☐ Top 5 recomendaciones priorizadas (impact × feasibility)
  ☐ Executive summary deck (15-20 slides)
  ☐ Presentación C-level realizada
  ☐ Q&A y feedback incorporado
```

---

### 2.3 Roles

```yaml
PMO_Lead:
  - Coordinar entrevistas
  - Collect metrics de sistemas
  - Análisis antipatrones
  
Sponsor:
  - Aprobar access a sistemas sensitivos
  - Facilitar calendarios C-level para entrevistas
  - Attend presentación final
  
Coalition:
  - Proveer domain expertise para interpretation
  - Validar findings (smell test)
  - Decidir priorization recomendaciones
```

---

### 2.4 Deliverables

```yaml
D1_Diagnostic_Report:
  Contenido:
    - Executive Summary (2 páginas)
    - H_Score: Actual + Breakdown por observable
    - Antipatrones detectados (top 10, severity ranking)
    - Root cause analysis (cadena causal)
    - Recomendaciones (top 5, impact estimado)
  Formato: PDF + Presentación
  Audiencia: C-level + Coalition
  
D2_Metrics_Baseline:
  Contenido:
    - 11 observables raw data
    - Trend histórico (6-12 meses si disponible)
    - Benchmarks externos (si disponibles)
  Formato: Dashboard (Tableau, Looker, o similar)
  Audiencia: PMO + Data team
  
D3_Recommendation_Backlog:
  Contenido:
    - Lista completa recomendaciones (15-20 típico)
    - Priorization matrix (2×2: impact × feasibility)
    - Effort estimates (T-shirt sizing)
    - Dependencies mapping
  Formato: Spreadsheet + Jira/Asana
  Audiencia: PMO + Coalition
```

---

### 2.5 Gates

```yaml
G1_Diagnóstico_Acceso:
  Timing: Fin Semana 1
  Ver: §1.5 Gates_Inventory
  
G2_Datos_Suficientes:
  Timing: Fin Semana 3
  Ver: §1.5 Gates_Inventory
  
G3_Budget_Aprobado:
  Timing: Fin Semana 4
  Ver: §1.5 Gates_Inventory
  Crítico: Sin budget aprobado, STOP (no proceder Fase 2)
```

---

### 2.6 Métricas

```yaml
Leading_Indicators:
  - Entrevistas completadas / target (30)
  - Data quality score por observable (target >80%)
  - Stakeholder engagement rate (attendance, responsiveness)
  
Lagging_Indicators:
  - H_Score calculated (outcome primario)
  - Número antipatrones identificados
  - Budget approval (binary: Y/N)
```

## §3. FASE 2: DISEÑO

### 3.1 Objetivo

```yaml
Input: Top 5 recomendaciones (Fase 1) + Budget aprobado
Output: Blueprint target state + Roadmap 12 meses + Investment plan
Duración: 4-6 semanas
```

---

### 3.2 Actividades

```yaml
Semana_1-2_Target_State_Design:
  
  Arquitectura_Organizacional:
    ☐ Org chart futuro (teams, roles, reporting lines)
    ☐ RACI matrices nuevas (decisiones, actividades)
    ☐ Governance model (ARB, decision rights, escalation paths)
    Ejemplo: Si REC-02 = "Cross-functional teams"
      → Diseñar 8 teams específicos: nombres, ownership, headcount, charter
  
  Arquitectura_Tecnológica:
    ☐ Architecture diagrams (current → target)
    ☐ CI/CD pipeline futuro (stages, gates, automation)
    ☐ Tech stack rationalization (consolidate, deprecate)
    Ejemplo: Si P23 (Feature Flags)
      → Tool selection: LaunchDarkly vs Unleash vs Custom
  
  Arquitectura_Procesos:
    ☐ Value stream maps futuros (idealized flow)
    ☐ Ceremonies design (Scrum, Kanban, hybrid)
    ☐ KPIs definition (métricas flow, quality, outcomes)

Semana_3-4_Gap_Analysis:
  
  ☐ Estado_Actual → Estado_Target mapping
  ☐ Por cada gap identificar:
      - ¿Qué debe cambiar? (scope cambio)
      - ¿Quién afectado? (people impact)
      - ¿Cuánto tiempo? (duration estimate)
      - ¿Qué risks? (probability × impact)
  
  Change_Impact_Assessment:
    ☐ Sample 20% org (representativo)
    ☐ Por persona evaluar:
        - Cambia rol: Sí/No
        - Cambia manager: Sí/No
        - Cambia herramientas: Sí/No
        - Cambia ubicación: Sí/No
        - Impact_Score: Alto/Medio/Bajo
    ☐ Aggregate: % Alto impact (target <30%)
  
  Risk_Catalog:
    ☐ Identificar 10-15 risks principales
    ☐ Por cada risk:
        - Descripción clara
        - Probabilidad (%)
        - Impacto (Alto/Medio/Bajo)
        - Mitigación plan
        - Owner
    Ejemplo:
      Risk: "Resistance managers funcionales (pierden autoridad)"
      Prob: 70% | Impact: Alto
      Mitigación: "Include en coalition, negotiate win-win roles"

Semana_5-6_Roadmap_Planning:
  
  Roadmap_12_Meses:
    ☐ Q1 (Meses 1-3): Quick wins + Pilot prep
    ☐ Q2 (Meses 4-6): Pilot execution + Learning
    ☐ Q3 (Meses 7-9): Scale (50% org) + Consolidate
    ☐ Q4 (Meses 10-12): Full adoption + Measure outcomes
  
  Investment_Plan:
    ☐ Headcount:
        - Transformation PMO: 2-3 FTE
        - Enabling teams (si P05): 1-2 FTE per 3-4 teams
        - Backfill: 10-20% capacity durante transition
    ☐ Budget:
        - Tooling: $50K-$200K (flags, CI/CD, analytics)
        - Consulting (si externa): $100K-$500K
        - Training: $20K-$50K
        - Contingency (15%): Auto-calculate
    ☐ ROI estimate: 2-3× investment Year 1 post-implementation
```

---

### 3.3 Roles

```yaml
Coalition:
  - Diseñar target state (workshops facilitados por PMO)
  - Validar design con stakeholders (5-10 entrevistas)
  - Aprobar roadmap y investment
  
PMO:
  - Facilitar design workshops
  - Documentar blueprints (Miro, Lucidchart, Confluence)
  - Análisis gap y risk
  - Build investment plan
  
Sponsor:
  - Review mid-point (semana 3)
  - Aprobar final design y budget
  - Champion coalition formation
```

---

### 3.4 Deliverables

```yaml
D1_Target_State_Blueprint:
  Contenido:
    - Org chart futuro (visual + narrativa)
    - RACI matrices (5-10 procesos críticos)
    - Architecture diagrams (tech + data)
    - Process workflows (value streams)
  Formato: Confluence/Notion + Diagrams
  
D2_Gap_Analysis:
  Contenido:
    - Current → Target mapping
    - Change impact assessment
    - Risk catalog + mitigations
  Formato: Spreadsheet + Risk register
  
D3_Transformation_Roadmap:
  Contenido:
    - Timeline 12 meses (Gantt)
    - Milestones y dependencies
    - Investment plan detallado
  Formato: Project management tool (Asana, Jira)
  
D4_Coalition_Charter:
  Contenido:
    - 8-12 nombres (roles, commitment)
    - Operating model (meeting cadence, decision rights)
    - Success criteria transformation
  Formato: 1-pager signed
```

---

### 3.5 Gates

```yaml
G4_Target_State_Validado:
  Timing: Semana 4
  Ver: §1.5 Gates_Inventory
  Crítico: Sin validación stakeholders, re-design needed
  
G5_Coalition_Formada:
  Timing: Fin Semana 6
  Ver: §1.5 Gates_Inventory
  Crítico: Sin coalition, NO proceder (failure rate >90%)
```

---

### 3.6 Métricas

```yaml
Leading_Indicators:
  - Design workshops completados (target: 4-6)
  - Validation interviews completadas (target: 10)
  - Coalition members recruited (target: 8-12)
  
Lagging_Indicators:
  - Target state validation score (target: >80% approval)
  - Coalition formed (binary: Y/N)
  - Roadmap approved (binary: Y/N)
```
```

---

Continúo con §4. FASE 3: PREPARACIÓN...

*Viewed [A3_Diagnostico.md](file:///Users/felixsanhueza/fx_felixiando/kernel/APLICACION/A3_Diagnostico.md) *

### User Input

si

### Planner Response

# §4. FASE 3: PREPARACIÓN

```markdown
## §4. FASE 3: PREPARACIÓN

### 4.1 Objetivo

```yaml
Input: Target state blueprint + Coalition formada
Output: Org preparada para transition (comunicada, entrenada, sistemas ready)
Duración: 4-8 semanas
```

---

### 4.2 Actividades

```yaml
Semana_1-2_Comunicación:
  
  Town_Hall_Kickoff:
    ☐ Audiencia: All-hands (toda org)
    ☐ Duración: 60 min
    ☐ Speakers: Sponsor + Coalition lead
    ☐ Contenido:
        - Por qué transformamos (pain actual, data H_Score)
        - Visión target state (org chart, workflows)
        - Timeline (cuándo cada quien afectado)
        - FAQ top 10 (anticipar concerns)
        - Q&A open (20 min mínimo)
    ☐ Grabación compartida (para quienes no asistieron)
    Principio: Transparencia > "Corporate BS"
  
  Communication_Plan_Ongoing:
    ☐ Bi-weekly updates (newsletter + Slack)
    ☐ Canales:
        - Email C-level → all company
        - Slack #transformation (AMA abierto)
        - Manager cascade (talking points provistos)
    ☐ Mensajes clave:
        - "Por qué" (business case con data)
        - "WIIFM" (What's In It For Me - beneficios personales)
        - "Cómo participo" (feedback loops, surveys)

Semana_3-4_Training:
  
  Module_1_All_Hands (2h):
    ☐ Intro KERNEL framework (invariantes, principios)
    ☐ Target workflows (cómo operarán cross-functional teams)
    ☐ Nuevas herramientas (feature flags, Kanban boards, CI/CD)
    ☐ Delivery: Virtual grabado + Live Q&A
    ☐ Attendance: >90% target (mandatory, tracked)
  
  Module_2_Managers (4h):
    ☐ Leadership durante transformación
    ☐ Managing resistance (4 tipos, ver D3 §7)
    ☐ Coaching teams through change
    ☐ 1:1s empathy techniques
    ☐ Delivery: Presencial (workshops interactivos)
    ☐ Attendance: 100% managers (non-negotiable)
  
  Module_3_Technical (8h, solo engineering):
    ☐ CI/CD nuevo pipeline (hands-on labs)
    ☐ Feature flags operación (LaunchDarkly workshop)
    ☐ Pair programming IA (si aplica en target state)
    ☐ Test automation standards
    ☐ Delivery: Hands-on labs (sandbox environments)
    ☐ Quiz post-training: 80% pass rate target
  
  Module_4_Pilot_Teams_Intensivo (16h):
    ☐ Deep-dive target state (workflows detallados)
    ☐ Pilot execution plan (semana a semana)
    ☐ Metrics collection (qué medir, cómo)
    ☐ Retrospectiva facilitation
    ☐ Delivery: 2 días presenciales
    ☐ Solo 2 teams piloto (12-18 personas)

Semana_5-8_Systems_Setup:
  
  Infrastructure:
    ☐ CI/CD pipeline configurado:
        - Staging environment
        - Production environment
        - Rollback procedures automated
    ☐ Feature flags platform deployed:
        - Tool: LaunchDarkly/Unleash/Custom
        - Access provisioned (all engineers)
        - Monitoring dashboards
    ☐ Metrics infrastructure:
        - H_Score automation (data pipelines)
        - Flow metrics (cycle time, throughput, WIP)
        - Dashboards públicos (Grafana, Tableau)
  
  Governance_Systems:
    ☐ ARB calendar establecido (weekly slot, recurring)
    ☐ Decision log template + Confluence space
    ☐ OKRs templates + Q planning timeline
    ☐ Retrospectiva templates (Miro boards)
  
  Documentation:
    ☐ Runbooks actualizados (nuevos workflows)
    ☐ Team charters escritos (8 teams si target)
    ☐ RACI matrices publicadas (Confluence/Notion)
    ☐ Onboarding guide new hires (incluye KERNEL)
  
  Pilot_Preparation:
    ☐ 2 teams seleccionados (criterios §5.1)
    ☐ Pilot readiness checklist 100%:
        - Team training completed
        - Tools access verified
        - Charter signed
        - Kickoff meeting scheduled
```

---

### 4.3 Roles

```yaml
PMO:
  - Organizar town hall y trainings
  - Setup infrastructure y tools
  - Coordinar pilot team selection
  - Preparar communication materials
  
Coalition:
  - Speak en town hall (champion cambio)
  - Participate trainings como subject matter experts
  - Validar documentation y runbooks
  - Seleccionar pilot teams (con managers)
  
Sponsor:
  - Open town hall (keynote 10 min)
  - Aprobar communication messages
  - Remover blockers infra (budget, priorities)
  
Line_Managers:
  - Cascade communication en 1:1s
  - Ensure team attendance trainings
  - Nominar pilot team members (si aplica)
```

---

### 4.4 Deliverables

```yaml
D1_Communication_Package:
  - Town hall recording + slides
  - FAQ document (15-20 preguntas)
  - Newsletter template (bi-weekly)
  - Manager talking points
  
D2_Training_Materials:
  - 4 módulos grabados + slides
  - Hands-on lab instructions
  - Quiz assessments
  - Attendance tracking (>90% all-hands)
  
D3_Systems_Ready:
  - CI/CD pipeline live en staging
  - Feature flags platform deployed
  - Metrics dashboards operacionales
  - Documentation space populated
  
D4_Pilot_Ready_Checklist:
  - 2 teams seleccionados
  - Readiness checklist 100% completado
  - Pilot kickoff meeting scheduled (Fase 4 Week 1)
```

---

### 4.5 Gates

```yaml
G6_Communication_Reach:
  Timing: Semana 2
  Ver: §1.5 Gates_Inventory
  Criterio: >85% org aware (survey validation)
  
G7_Pilot_Teams_Ready:
  Timing: Fin Semana 8
  Ver: §1.5 Gates_Inventory
  Criterio: 2 teams volunteer + trained + systems access
  Crítico: Sin pilot teams ready, delay Fase 4
```

---

### 4.6 Métricas

```yaml
Leading_Indicators:
  - Town hall attendance (target >80%)
  - Training completion rate (target >90%)
  - Pilot volunteers count (target: 3-4 teams offer, select 2)
  - Communication survey sentiment (target >65/100)
  
Lagging_Indicators:
  - Systems deployed (binary: Y/N per system)
  - Pilot teams ready (binary: Y/N)
  - Awareness survey (target: >85% aware)
```

## §5. FASE 4: PILOTO

### 5.1 Objetivo

```yaml
Input: 2 teams ready + Target state blueprint + Systems live
Output: Validated target state + Learnings para scale + Go/No-Go decision
Duración: 8-12 semanas
```

---

### 5.2 Pilot Team Selection

```yaml
Criterios_Obligatorios:
  
  ☐ High-performing team:
      Rationale: Piloto no es rescate, es validation
      Check: Team velocity top 30% org
  
  ☐ Representative work:
      Rationale: Aprendizajes deben ser generalizable
      Check: Típico producto/servicio (no edge case)
  
  ☐ Manager champion:
      Rationale: Sin buy-in manager, piloto fracasa
      Check: Manager volunteer + entusiasta (no assignado)
  
  ☐ Team size óptimo:
      Rationale: Two-pizza team (communication overhead minimal)
      Check: 5-9 personas
  
  ☐ Tenure adecuado:
      Rationale: Context org necesario para validar cambios
      Check: Avg tenure >6 meses
  
  ☐ Volunteer-based:
      Rationale: Commitment > Compliance
      Check: Team voluntarily opts-in (no mandated)

Ejemplo_Selección:
  Pilot_A:
    Team: "Payments Team"
    Size: 7 personas
    Manager: Sarah (champion, 3 años tenure)
    Work: Core product (representative)
    Velocity: Top 20%
  
  Pilot_B:
    Team: "Catalog Team"
    Size: 6 personas
    Manager: John (open-minded, 2 años tenure)
    Work: Critical service (representative)
    Velocity: Top 30%
```

---

### 5.3 Actividades

```yaml
Semana_1-4_Pilot_Execution:
  
  Week_1_Transition:
    ☐ Pilot teams transition a target state
    ☐ Ejemplo: Si cross-functional design
        → Reassign QA engineer full-time a team
        → Reassign designer 50% a team
    ☐ Nuevo workflow kickoff (ceremonies, tools)
    ☐ Daily check-ins PMO con teams (15 min)
    ☐ Baseline metrics captured (pre-pilot)
  
  Week_2-3_Operate_New_Model:
    ☐ Teams operan en target state
    ☐ PMO observa (embedded 50% tiempo)
    ☐ Metrics tracking continuo:
        - Cycle time (per work item)
        - Throughput (items completados/semana)
        - WIP (work in progress)
        - Team satisfaction (survey semanal, 5 min)
    ☐ Issues log actualizado diario
  
  Week_4_Mid-Pilot_Retro:
    ☐ Retrospectiva profunda (2h per team)
    ☐ Qué funciona / qué no funciona
    ☐ Ajustes menores aprobados:
        Principio: OK cambiar proceso si data muestra problem
        Ejemplo: "Daily standups 15 min insuficiente para 7 personas"
        → Ajuste: Split en Backend (8 min) + Frontend (8 min)
    ☐ Adjustments implementados Week 5

Semana_5-8_Learning_Iteration:
  
  Data_Collection_Intensiva:
    Quantitative:
      ☐ Cycle time: Pilot vs Control teams (comparación)
      ☐ Throughput: Items/semana (trend)
      ☐ Incident rate: Bugs escaped prod (quality)
      ☐ Deployment frequency: Releases/semana
    
    Qualitative:
      ☐ Weekly surveys pilot teams (5 preguntas, <5 min)
      ☐ Bi-weekly retrospectivas (profundas)
      ☐ Anecdotes collection (sorpresas, pain points)
      ☐ 1:1s con cada miembro (PMO, 30 min)
  
  Adjustments_Iterativos:
    ☐ Si issue detectado → Diagnose root cause
    ☐ Propose ajuste → Validate con team
    ☐ Implement → Measure impact (1-2 semanas)
    ☐ Document learning (what worked, what didn't)
    
    Ejemplo_Real:
      Issue: "Cross-functional daily 15 min no suficiente"
      Root_Cause: 7 personas (3 backend, 3 frontend, 1 QA) = too many updates
      Ajuste: Split standups por discipline
      Impact: Team satisfaction +15 pts, cycle time unchanged
      Learning: "Standup size limit = 5 personas, split si más"

Semana_9-12_Pilot_Wrap-Up:
  
  Week_9-10_Data_Consolidation:
    ☐ Finalize metrics collection
    ☐ Statistical analysis (significance tests)
    ☐ Comparar pilot vs control teams (A/B comparison)
    ☐ Aggregate learnings (categorize por theme)
  
  Week_11_Pilot_Report:
    ☐ Executive summary (2 páginas)
    ☐ Metrics before/after (dashboards visuales)
    ☐ Lessons learned (top 10, categorized)
    ☐ Adjustments needed para rollout
    ☐ Go/No-Go recommendation (explicit)
  
  Week_12_Gate_Review:
    ☐ Presentación a Coalition + Sponsor (90 min)
    ☐ Q&A profundo (30 min)
    ☐ Decision: Go / Mixed / Fail (ver §5.6)
```

---

### 5.4 Roles

```yaml
Pilot_Teams:
  - Operar en target state (100% commitment)
  - Proveer feedback continuo (surveys, retros)
  - Experimentar y ajustar (con PMO support)
  
PMO:
  - Embedded support pilot teams (50% tiempo)
  - Metrics collection y analysis
  - Facilitate retros y workshops
  - Preparar pilot report
  
Coalition:
  - Review bi-weekly (progress, blockers)
  - Aprobar adjustments mayores (si cambio design)
  - Gate review final (Go/No-Go decision)
  
Sponsor:
  - Remove blockers escalados
  - Gate review final (Go/No-Go approval)
```

---

### 5.5 Deliverables

```yaml
D1_Pilot_Execution_Log:
  - Daily standup notes (issues, decisions)
  - Weekly metrics snapshots (quantitative)
  - Retrospectiva summaries (qualitative)
  
D2_Metrics_Dashboard:
  - Pilot vs Control comparison (visual)
  - Trends 12 semanas (cycle time, throughput, satisfaction)
  - Statistical significance tests
  
D3_Lessons_Learned_Catalog:
  - Top 10 learnings (categorized)
  - What worked (replicate en scale)
  - What didn't work (adjust para scale)
  - Surprises (unexpected insights)
  
D4_Pilot_Report:
  - Executive summary (2 pgs)
  - Metrics before/after (dashboards)
  - Lessons learned (detailed)
  - Adjustments para rollout (specific)
  - Go/No-Go recommendation (explicit + rationale)
```

---

### 5.6 Success Criteria & Gate

```yaml
G8_Pilot_Success:
  Timing: Semana 12
  Ver: §1.5 Gates_Inventory
  
  Quantitative_Gates:
    ☐ Cycle time: -20%+ vs baseline (mejora significativa)
    ☐ Team satisfaction: >75/100 (vs ~60 baseline típico)
    ☐ H_Score pilot teams: +10 pts mínimo
    ☐ No degradation quality (incident rate estable o mejor)
  
  Qualitative_Gates:
    ☐ Team recommendation: >80% "sí, rollout a otros"
    ☐ Manager champions: Advocate publicly (town halls)
    ☐ No blockers críticos: Sin issues sin solución identificada
  
  Decision_Matrix:
    
    SUCCESS (Go → Fase 5):
      Condición: 4+ quantitative gates met + 3 qualitative gates met
      Acción: Proceder Scale inmediatamente
      Comunicación: Celebrate success, share learnings org-wide
    
    MIXED (Extend 4 semanas):
      Condición: 2-3 quantitative gates met + 2 qualitative gates met
      Acción: Address gaps específicos, re-measure
      Comunicación: Transparente sobre gaps, show improvement plan
    
    FAILURE (Pause):
      Condición: <2 quantitative gates met OR blockers críticos
      Acción: Deep-dive root cause, major redesign needed
      Comunicación: Honest assessment, no sugar-coating
      
      Typical_Failure_Causes:
        - Target state design flawed (technical o org)
        - Insufficient resources (teams overloaded)
        - Leadership support lost (coalition fracturó)
        - External shock (market crisis, reorg conflict)
```

---

### 5.7 Métricas

```yaml
Leading_Indicators:
  - Weekly survey sentiment (target: trend upward)
  - Issues log count (target: decreasing semana 4+)
  - Retro action items closed (target: >80%)
  
Lagging_Indicators:
  - Cycle time improvement (target: -20%+)
  - Team satisfaction (target: >75/100)
  - Pilot success (binary: Go/Mixed/Fail)
```

## §6. FASE 5: ESCALAMIENTO

### 6.1 Objetivo

```yaml
Input: Pilot success + Lessons learned + Go decision
Output: Target state deployed org-wide + H_Score improvement validado
Duración: 12-24 semanas (depende org size)
```

---

### 6.2 Wave Planning

```yaml
Principio_Incremental:
  Approach: Wave-by-wave rollout (NO big-bang)
  Rationale: 
    - Manage risk (failure de 1 wave no colapsa org)
    - Apply learnings (cada wave informa siguiente)
    - Manage capacity (PMO support finito)

Wave_Structure:
  
  Wave_1 (Semanas 1-6):
    Teams: 2-3 nuevos (total 4-5 con pilots)
    Criterios_Selección:
      - Managers entusiastas (early adopters)
      - Low risk (non-critical path inicial)
      - Geographic/functional diversity (learning amplification)
    Support_Level: PMO full-time embedded (50% per team)
    
  Wave_2 (Semanas 7-12):
    Teams: 4-6 nuevos (total 8-11 teams)
    Criterios_Selección:
      - Mayoría "early majority" (pragmatists)
      - Include algunos skeptics (address resistance early)
      - Critical path teams (core business)
    Support_Level: PMO part-time (25% per team)
    Peer_Support: Pilot teams coach new teams (buddy system)
    
  Wave_3 (Semanas 13-18):
    Teams: Restantes (total org coverage)
    Criterios_Selección:
      - Laggards y teams complejos (edge cases)
      - Geographies remotas o BUs especiales
    Support_Level: Self-service + PMO escalations only
    Peer_Support: Wave 1-2 teams mentorship
    
  Buffer_Consolidación (Semanas 19-24):
    Focus: Stabilization completa
    Actividades:
      - Address edge cases no resueltos
      - Refinements post-scale
      - Handoff preparation a BAU

Scaling_Factors:
  Org_Size:
    <100_personas: 1 wave suficiente (8 semanas)
    100-500: 3 waves (estándar, 18 semanas)
    500-1000: 4-5 waves (+6-8 semanas)
    >1000: Sub-waves por BU/geography (+12-18 semanas)
```

---

### 6.3 Execution Pattern per Wave

```yaml
Pre-Wave (2 semanas antes):
  
  Semana_-2:
    ☐ Teams seleccionados notificados
    ☐ Manager briefings (1:1, 30 min cada uno)
    ☐ Team briefings (all-hands team, 45 min)
    ☐ Training scheduled (según Module 1-3, §4.2)
  
  Semana_-1:
    ☐ Training completado (attendance verified)
    ☐ Tools access provisioned (CI/CD, flags, dashboards)
    ☐ 1:1s individuales (manager con cada persona, 15 min)
    ☐ Team charter draft preparado
    ☐ Transition kickoff meeting scheduled

Wave_Execution (6 semanas):
  
  Week_1_Transition:
    ☐ Kickoff meeting (team + PMO, 2h)
    ☐ Target state activation:
        - Org changes (si reassignments)
        - Workflow changes (ceremonies, tools)
        - Baseline metrics captured
    ☐ Daily check-ins PMO (15 min, primeros 5 días)
  
  Week_2-5_Operate_Support:
    ☐ Teams operan en target state
    ☐ PMO support según nivel wave (full/part-time/escalation)
    ☐ Weekly retrospectivas (identify issues early)
    ☐ Issues log actualizado
    ☐ Peer support buddy system (Wave 1-2 teams ayudan)
    ☐ Metrics tracking continuo
  
  Week_6_Consolidation:
    ☐ Wave retrospectiva (all teams wave, 2h)
    ☐ Metrics review (vs success criteria)
    ☐ Lessons learned capture
    ☐ Adjustments identification para next wave
    ☐ Celebration (success ritual, team recognitions)

Post-Wave:
  ☐ Metrics consolidated (quantitative)
  ☐ Issues log reviewed (qualitative)
  ☐ Adjustments documentados (para next wave)
  ☐ G9 Gate review (Go/No-Go next wave)
```

---

### 6.4 Resistance Management

```yaml
Framework: Ver DOMINIOS/D3_Decision.md §7 (detalle completo)

Tipos_Resistance:
  
  1_Cognitiva (No entienden):
     Síntoma: "No veo por qué cambiar"
     Diagnóstico: Falta claridad business case
     Remediación:
       - Re-comunicar "por qué" (data, pilot results)
       - Case studies internos (pilot teams testimonials)
       - 1:1s explicar impact personal
  
  2_Emocional (Miedo):
     Síntoma: "¿Qué pasa conmigo?"
     Diagnóstico: Uncertainty sobre futuro personal
     Remediación:
       - 1:1s empathy (manager, 30 min)
       - Address fears específicos (job security, competence)
       - Safety nets (escape hatches si nuevo rol no funciona)
       Ejemplo: "Si cross-functional role no funciona, puedes volver a functional team primeros 6 meses"
  
  3_Política (Pierden poder):
     Síntoma: Active blocking (overt o covert)
     Diagnóstico: Legitimate loss (autoridad, recursos, status)
     Remediación:
       - Negotiate win-win (find new role value-add)
       - Include en coalition (co-opt)
       - Override si blocker crítico (last resort, sponsor decision)
       Ejemplo: Manager funcional pierde reports → Offer lead platform team o center of excellence
  
  4_Legítima (Concerns válidos):
     Síntoma: Articulate objections con data
     Diagnóstico: Design flaw o edge case no contemplado
     Remediación:
       - ESCUCHAR (no dismiss)
       - Investigate concern (puede ser real issue)
       - Adjust design si válido
       Ejemplo: "Edge case regulatory compliance no contemplado" → Address en design

Escalation_Path:
  
  Level_1_Team_Manager:
    Scope: Individual resistance, minor issues
    Response_Time: 24-48h
    Approach: 1:1s, coaching, clarification
  
  Level_2_PMO:
    Scope: Team-level resistance, process issues
    Response_Time: 48-72h
    Approach: Workshops, re-training, peer support
  
  Level_3_Coalition:
    Scope: Cross-team issues, design concerns
    Response_Time: 1 semana
    Approach: Design adjustments, policy changes
  
  Level_4_Sponsor:
    Scope: Blockers críticos, political resistance
    Response_Time: 1 semana (urgent), 2 semanas (normal)
    Approach: Executive intervention, overrides, consequences

Proactive_Mitigation:
  ☐ Early identification (surveys, manager feedback)
  ☐ Address antes se convierte en blocker
  ☐ Transparent communication (no surprises)
  ☐ Celebrate early adopters (positive reinforcement)
```

---

### 6.5 Roles

```yaml
PMO:
  - Execute wave plans (coordination día a día)
  - Support teams según nivel wave
  - Track metrics y issues
  - Facilitate retrospectivas
  - Escalate blockers
  Intensity: Peak durante Fases 5 (full-time 2-3 personas)
  
Coalition:
  - Review bi-weekly (progress, blockers)
  - Gate reviews per wave (G9)
  - Address escalations Level 3
  - Champion cambio en sus áreas
  
Sponsor:
  - Remove blockers Level 4
  - Communicate milestones org-wide
  - Gate approvals críticos
  
Line_Managers:
  - Execute transition en sus teams
  - 1:1s empathy continuo
  - Identify resistance early
  - Coach teams day-to-day
  Intensity: Peak durante transition (extra 3-5h/semana)
  
Pilot_Teams:
  - Peer coaching Wave 2-3 teams
  - Share learnings (tech talks, wikis)
  - Ambassadors cambio
```

---

### 6.6 Deliverables

```yaml
D1_Wave_Execution_Plans:
  - Wave 1-3 detailed plans (timeline, teams, support)
  - Team selection rationale
  - Training schedules
  
D2_Metrics_Dashboards:
  - Real-time progress (teams transitioned, issues count)
  - Success metrics per wave (cycle time, satisfaction)
  - Trend analysis (mejorando, estable, degradando)
  
D3_Issues_Lessons_Log:
  - Issues identificados y resolved per wave
  - Lessons learned aplicados (what changed wave a wave)
  - Best practices emergentes
  
D4_H_Score_Remeasurement:
  - H_Score final (post-Wave 3)
  - Improvement vs baseline (+15-25 pts esperado)
  - Observable breakdown (cuáles mejoraron más)
```

---

### 6.7 Gates

```yaml
G9_Scale_Validated:
  Timing: Post cada wave (semana 6, 12, 18)
  Ver: §1.5 Gates_Inventory
  
  Criterio: >70% teams wave actual met success criteria
  
  Success_Criteria_per_Team:
    ☐ Cycle time: -15%+ vs baseline (o al menos no degradation)
    ☐ Team satisfaction: >70/100
    ☐ No blockers críticos sin resolver
    ☐ Metrics tracking operacional
  
  Decision_Logic:
    IF >70% teams success:
      → GO next wave (proceder según plan)
    
    IF 50-70% teams success:
      → CONDITIONAL: Address issues, delay next wave 2 semanas
    
    IF <50% teams success:
      → PAUSE: Deep-dive root cause
          Possible_Causes:
            - Design flawed (need adjustments)
            - Support insuficiente (need more PMO capacity)
            - Resistance no manejada (need coalition intervention)
          Action: Fix root cause antes continuar

Final_Gate_Post_Wave_3:
  Criterio_Adicional: H_Score improvement >15 pts vs baseline
  Si_NO: Diagnóstico profundo qué no funcionó
```

---

### 6.8 Métricas

```yaml
Leading_Indicators:
  - Teams transitioned per wave (target: 100% planned)
  - Training completion (target: >90% per wave)
  - Issues resolution rate (target: >80% resolved <2 semanas)
  - Weekly survey sentiment (target: trend positivo)
  
Lagging_Indicators:
  - Cycle time org-wide (target: -30%+ vs baseline)
  - Deployment frequency (target: +200%+)
  - Team satisfaction avg (target: >70/100)
  - H_Score final (target: +15-25 pts vs baseline)
  - Turnover rate (target: -20%+ vs baseline)
```

## §7. FASE 6: SOSTENIBILIDAD

### 7.1 Objetivo

```yaml
Input: Target state deployed org-wide + H_Score improvement validado
Output: Cambios institucionalizados + PMO handoff a BAU
Duración: Continuo (18-24 meses handoff timeline)
```

---

### 7.2 Monitoring Continuo

```yaml
H_Score_Tracking (Mensual):
  
  ☐ Calcular 11 observables cada mes
  ☐ Dashboard público (toda org visibility)
  ☐ Trend analysis:
      - Mejorando: H_Score +2-5 pts/quarter (excelente)
      - Estable: H_Score ±2 pts (aceptable)
      - Degradando: H_Score -3+ pts (alerta)
  
  Alertas_Proactivas:
    Yellow_Alert (H_Score cae 5-10 pts):
      → Diagnóstico root cause (PMO lead)
      → Review próximo QBR
      → Corrective actions identificadas
    
    Red_Alert (H_Score cae >10 pts):
      → Intervention inmediata (Coalition + Sponsor)
      → Emergency meeting (48h)
      → Reactivate PMO si necesario (temporal)

Flow_Metrics_Tracking (Semanal):
  
  ☐ Cycle time por team (dashboard team-level)
  ☐ Throughput (items/semana)
  ☐ WIP (work in progress, target: controlled)
  ☐ Deployment frequency
  ☐ Incident rate
  
  Team_Health_Checks (Mensual):
    ☐ Survey 5 preguntas (5 min, toda org)
    ☐ Questions:
        - Satisfaction: "¿Cómo te sientes en tu team?" (1-10)
        - Autonomy: "¿Puedes decidir cómo trabajar?" (1-10)
        - Impact: "¿Ves impacto de tu trabajo?" (1-10)
        - Collaboration: "¿Colaboración efectiva?" (1-10)
        - Sustainable_Pace: "¿Ritmo sostenible?" (1-10)
    ☐ Target: Avg >7/10 todas preguntas
    ☐ Alert si team <6/10 alguna pregunta
```

---

### 7.3 Governance Institucionalizado

```yaml
Quarterly_Business_Review (QBR):
  
  Frecuencia: Trimestral
  Duración: 2 horas
  Participantes: C-level + VPs + PMO (inicial) → Data team (post-handoff)
  
  Agenda_Estándar:
    1. H_Score_Trend (30 min):
       - Actual vs target
       - Observable breakdown
       - Comparación quarters anteriores
    
    2. Top_3_Wins (15 min):
       - Celebrar successes
       - Share learnings
       - Recognition teams
    
    3. Top_3_Challenges (15 min):
       - Issues emergentes
       - Degradations detectadas
       - Risks próximo quarter
    
    4. Roadmap_Adjustments (30 min):
       - OKRs próximo quarter
       - Initiatives: Continue / Kill / Start
       - Budget allocation
    
    5. Actions_Decisions (30 min):
       - Decisiones específicas (owner + deadline)
       - Escalations needed
  
  Output:
    ☐ OKRs ajustados (si necesario)
    ☐ Budget allocated próximo quarter
    ☐ Action items log (tracked hasta completion)

Annual_Retrospectiva_Organizacional:
  
  Frecuencia: Anual
  Formato: Survey (toda org) + Focus groups (30-50 personas sample)
  
  Survey_Questions (15-20 preguntas, 10 min):
    - "¿Transformación cumplió promesas?" (1-10)
    - "¿Qué mejoró más?" (open text)
    - "¿Qué aún falta?" (open text)
    - "¿Recomendarías KERNEL a otra org?" (NPS)
    - "¿Ritmo cambio fue apropiado?" (too fast / right / too slow)
  
  Focus_Groups (90 min, 6-8 personas):
    - Diverse composition (roles, tenure, skeptics + champions)
    - Facilitated por external (si posible, menos bias)
    - Deep-dive themes survey
    - Generate insights próximo año
  
  Output:
    ☐ Annual report (state of transformation)
    ☐ Learnings catalog (what worked, what didn't)
    ☐ Recommendations año siguiente
```

---

### 7.4 Continuous Improvement

```yaml
Kaizen_Culture:
  
  Team_Retrospectivas (Bi-weekly):
    ☐ Toda team, 60 min
    ☐ Format: What went well / What didn't / Actions
    ☐ Action items: Max 3 per retro (focus)
    ☐ Follow-up: Review actions retro anterior (accountability)
    ☐ Principle: Small experiments continuo (vs big changes)
  
  Experiments_Framework:
    ☐ Team propone experiment (hypothesis clear)
    ☐ Small scope (<2 semanas, low risk)
    ☐ Measure impact (metrics antes/después)
    ☐ Decision: Keep / Adjust / Discard
    ☐ Share learning (si success, scale; si failure, evitar repetir)
    
    Ejemplo:
      Hypothesis: "Async standups (Slack) reducirán cycle time vs sync meetings"
      Experiment: 2 semanas async, track cycle time + team satisfaction
      Result: Cycle time unchanged, satisfaction -5 pts
      Decision: Discard, volver sync standups
      Learning: "Sync importante para team cohesion, overhead aceptable"

Pattern_Library_Evolution:
  
  ☐ Si team descubre nuevo patrón efectivo:
      → Document (template: Context / Problem / Solution / Evidence)
      → Validate con 2-3 teams (replication)
      → Si validated → Add KERNEL pattern library (P54+)
      → Share org-wide (tech talk, wiki)
  
  ☐ Si antipatrón emerge (regression o nuevo):
      → Alert PMO / Data team
      → Root cause analysis
      → Remediation plan
      → Document (AP36+)
      → Preventive measures (monitoring, training)

Training_Refresh:
  
  New_Hires_Onboarding:
    ☐ KERNEL intro (2h, primeros 30 días)
    ☐ Content:
        - Framework overview (invariantes, principios)
        - Org workflows actuales (post-transformation)
        - Tools y systems
        - Team charters y expectations
    ☐ Delivery: Grabado + Live Q&A bi-weekly
  
  Annual_Refresher (All org):
    ☐ "What's New in KERNEL" (1h, town hall format)
    ☐ Content:
        - Año en review (wins, learnings)
        - Pattern/anti-pattern updates
        - Próximo año priorities
    ☐ Delivery: Live + grabación
```

---

### 7.5 PMO Handoff a BAU

```yaml
Handoff_Timeline: Meses 18-24 post-kick-off inicial

Mes_18_Reduction:
  PMO_Capacity:
    - De 2-3 personas full-time → 1 persona full-time
    - Reduction 70% headcount
  
  Responsibilities_Transitioned:
    ☐ Metrics tracking → Data team (automation)
    ☐ Team support → Line managers (capability built)
    ☐ Training delivery → HR / Learning team
  
  PMO_Focus_Remaining:
    - QBR facilitation
    - H_Score monitoring
    - Issues escalation management (complex only)

Mes_24_Dissolution:
  PMO_Capacity:
    - PMO formalmente disuelto
    - Persona remaining reassigned (product, ops, o exit)
  
  Responsibilities_Final_Handoff:
    ☐ H_Score tracking → Data team (fully automated)
    ☐ QBR → C-level existing meeting (embedded agenda)
    ☐ Training → HR onboarding process (standard)
    ☐ Continuous improvement → Line managers + teams (ownership)
  
  Validation_Handoff_Ready:
    ☐ H_Score stable >80 por 2 quarters consecutivos
    ☐ <5% teams reverting old ways
    ☐ Managers confident owning continuous improvement
    ☐ No dependency en PMO para operate
    ☐ Artifacts y documentation self-service

Post_Handoff_Governance:
  - QBR continúa (quarterly, C-level owned)
  - H_Score dashboard monitored (Data team)
  - Annual retrospectiva (HR facilitated)
  - Continuous improvement (teams owned)
```

---

### 7.6 Deliverables

```yaml
D1_Monitoring_Infrastructure:
  - H_Score dashboard automated (data pipelines)
  - Flow metrics dashboards (team + org level)
  - Alert systems configured (Yellow/Red alerts)
  
D2_Governance_Cadence:
  - QBR calendar (recurring quarterly)
  - Annual retrospectiva process (documented)
  - Decision log maintained (ongoing)
  
D3_Continuous_Improvement_Embedded:
  - Retros calendars (bi-weekly, all teams)
  - Experiments framework documented
  - Pattern library maintained (living document)
  
D4_PMO_Handoff_Complete:
  - Handoff checklist 100% (validation criteria met)
  - Responsibilities RACI transitioned
  - Documentation updated (runbooks, processes)
  - Transformation declared "complete" (celebration ritual)
```

---

### 7.7 Métricas Sostenibilidad

```yaml
Leading_Indicators:
  - H_Score trend (target: stable o mejorando)
  - Team health survey (target: >7/10 todas dimensiones)
  - Experiments count (target: 2-3 per team per quarter)
  - Training completion new hires (target: >95%)
  
Lagging_Indicators:
  - H_Score final stabilized (target: >80 sostenido 6+ meses)
  - Turnover rate (target: <10% anual)
  - NPS employees (target: >50, promoters > detractors)
  - PMO handoff complete (binary: Y/N, Mes 24)
```

## §8. SISTEMA DE GOBERNANZA

### 8.1 Principios Gobernanza

```yaml
G1_Transparencia:
  Definición: Decisiones visibles, rationale documentado
  Implementación:
    - Decision log público (Confluence/Notion)
    - Meetings con minuta compartida
    - Dashboard métricas accesible toda org
  
G2_Participación:
  Definición: Input stakeholders relevantes antes decisión
  Implementación:
    - RFC process (Requests for Comments)
    - Design reviews públicos
    - Survey feedback mechanisms
  
G3_Accountability:
  Definición: Owner explícito por decisión/outcome
  Implementación:
    - RACI matrices claras
    - OKRs con owners nombrados
    - Consequences (positive/negative) por performance
  
G4_Adaptabilidad:
  Definición: Adjust cuando evidencia muestra need
  Implementación:
    - Retrospectivas con action items
    - Metrics-driven pivots
    - "Strong opinions, weakly held"
  
G5_Subsidiarity:
  Definición: Decisiones al nivel más bajo competente
  Implementación:
    - Teams autonomía táctica
    - Escalation solo si cross-team o strategic
    - Empowerment guidelines explícitos
```

---

### 8.2 Decision Framework

```yaml
Decision_Types:
  
  Type_1_Reversible:
    Características:
      - Bajo costo revertir (<1 día effort)
      - Impacto localizado (1 team)
      - Sin dependencies críticas
    Process:
      - Owner: Team lead
      - Approval: Ninguna (autonomía completa)
      - Documentation: Optional (si learnings)
    Ejemplos:
      - Cambio nombre variable
      - Refactor internal module
      - A/B test feature flag
  
  Type_2_Difícil_Revertir:
    Características:
      - Alto costo revertir (días-semanas)
      - Impacto cross-team
      - Dependencies múltiples
    Process:
      - Owner: Product/Tech lead
      - Approval: ARB (Architecture Review Board)
      - Documentation: Mandatory (decision log)
    Ejemplos:
      - Cambio database schema
      - Nuevo tech stack component
      - API contract breaking change
  
  Type_3_Irreversible:
    Características:
      - Imposible revertir prácticamente
      - Impacto organizacional
      - Consecuencias largo plazo
    Process:
      - Owner: C-level
      - Approval: Board (si aplica)
      - Documentation: Extensive (decision record + rationale)
    Ejemplos:
      - Adquisición empresa
      - Pivot business model
      - Shutdown producto
      - Major layoff

ARB_Architecture_Review_Board:
  Composición: 4-6 personas (architects + tech leads senior)
  Frecuencia: Weekly (slot 60 min)
  Scope: Type-2 decisions técnicas
  Process:
    1. Submit RFC (48h antes, template estándar)
    2. Review async (comments pre-meeting)
    3. Meeting discussion (30 min per RFC)
    4. Decision: Approve / Reject / Conditional
    5. Record (decision log + broadcast)
  
  Decision_Criteria:
    - Alineación arquitectura target
    - TCO y ROI estimado
    - Risk assessment
    - Team capacity y expertise
```

---

### 8.3 Escalation Paths

```yaml
Path_Normal:
  
  L0_Individual:
    Scope: Trabajo propio, decisiones Type-1
    Response: Inmediata (autonomía)
  
  L1_Team:
    Scope: Trabajo equipo, dependencies internas
    Response: 24-48h (daily standup o async)
    Escalate_Si: Blocker no resuelto en 2 días
  
  L2_Cross_Team:
    Scope: Dependencies múltiples teams
    Response: 48-72h (sync cross-team meeting)
    Escalate_Si: Conflicto prioridades o no consensus
  
  L3_Product_Tech_Leadership:
    Scope: Strategic decisions, resource allocation
    Response: 1 semana (review semanal)
    Escalate_Si: Impacto business significativo
  
  L4_C_Level:
    Scope: Organizacional, irreversible, alta inversión
    Response: 2 semanas (QBR o ad-hoc)
    Escalate_Si: >$500K o >50 personas impact

Path_Crisis (Ver CORE/08):
  L0_Crisis_Team: Respuesta inmediata (minutos-horas)
  L1_Sponsor: Decisiones críticas (horas-días)
  No_Escalation_Normal: Bypass levels intermedios si crisis validated
```

---

### 8.4 Communication Protocols

```yaml
Cadencia_Standard:
  
  Daily_Standups (Team):
    Duración: 15 min
    Participantes: Team completo
    Formato: What done / What today / Blockers
    Output: Blockers identificados → Resolve same day
  
  Weekly_Team_Planning (Team):
    Duración: 60 min
    Participantes: Team + Product lead
    Formato: Review last week / Plan this week / Adjust priorities
    Output: Commitments próxima semana
  
  Bi-Weekly_Sprint_Review (Team + Stakeholders):
    Duración: 60 min
    Participantes: Team + Customers/Stakeholders invitados
    Formato: Demo trabajo completado / Feedback / Q&A
    Output: Feedback incorporado backlog
  
  Bi-Weekly_Retrospectiva (Team):
    Duración: 60 min
    Participantes: Team solo (safe space)
    Formato: What worked / What didn't / Actions
    Output: Max 3 action items (tracked)
  
  Monthly_All-Hands (Org):
    Duración: 60 min
    Participantes: Toda org
    Speakers: C-level + Teams (rotativo)
    Formato: Business update / Wins / Challenges / Q&A
    Output: Alignment org-wide
  
  Quarterly_QBR (C-level + Leadership):
    Duración: 2 horas
    Ver: §7.3 (detalle completo)

Comunicación_Async:
  
  Decision_Log:
    Frecuencia: Por decisión Type-2+
    Canal: Confluence/Notion
    Template: Context / Options / Decision / Rationale / Owner
  
  Newsletter_Transformation:
    Frecuencia: Bi-weekly durante Fases 2-5
    Canal: Email + Slack
    Contenido: Progress / Wins / Next steps / FAQ
  
  Tech_Talks:
    Frecuencia: Monthly (volunteer-based)
    Canal: Grabado + Live
    Contenido: Learnings técnicos, pattern sharing
```

---

### 8.5 Conflict Resolution

```yaml
Framework_Structured:
  
  Step_1_Identify:
    ☐ ¿Qué es el conflicto? (specific, not vague)
    ☐ ¿Quiénes involucrados? (personas, teams)
    ☐ ¿Tipo conflicto? (ver tipología)
  
  Step_2_Diagnose_Root_Cause:
    Tipo_A_Información:
      Causa: Falta datos, ambigüedad, malentendidos
      Fix: Compartir información, clarificar, alinear understanding
    
    Tipo_B_Intereses:
      Causa: Objetivos incompatibles (ej: velocity vs quality)
      Fix: Negotiate trade-offs, find win-win, escalate si zero-sum
    
    Tipo_C_Valores:
      Causa: Principios fundamentales opuestos (ej: autonomy vs control)
      Fix: Difícil; requiere leadership intervention, explicit choice
    
    Tipo_D_Relacional:
      Causa: History negativa, trust erosionado
      Fix: Facilitated conversation, reset expectations, a veces separation
  
  Step_3_Resolve:
    Approach_Colaborativo (Preferido):
      - Ambas partes input
      - Buscar solución win-win
      - Commitment mutual
    
    Approach_Compromise:
      - Split difference
      - Ambos ceden algo
      - Satisficing (no optimal para nadie)
    
    Approach_Autoritativo (Last resort):
      - Leader decide
      - Imposition top-down
      - Riesgo: Compliance sin buy-in
  
  Step_4_Document:
    ☐ Qué se decidió
    ☐ Por qué (rationale)
    ☐ Próximos pasos
    ☐ Review date (si experimental)

Escalation_Criteria:
  ☐ No resolution en 1 semana (L1 → L2)
  ☐ Impacto cross-team (L2 → L3)
  ☐ Bloquea critical path (any L → L3)
```

## §9. FRAMEWORK DE VALIDACIÓN

### 9.1 Métricas Universales

```yaml
Categorías_Ortogonales:
  
  M1_Flow_Efficiency:
    Definición: Qué tan suave fluye trabajo
    Métricas:
      - Cycle_Time: Tiempo commit → deploy (target: <2 días)
      - Throughput: Items completados/semana (trend upward)
      - WIP: Work in progress (target: <3 per persona)
      - Flow_Efficiency: % tiempo value-add vs wait (target: >40%)
    
  M2_Quality:
    Definición: Qué tan bien funciona output
    Métricas:
      - Defect_Rate: Bugs per 1000 LOC (target: <5)
      - Incident_Rate: Production incidents/mes (target: <2)
      - MTTR: Mean time to restore (target: <4h)
      - Test_Coverage: % code covered (target: >80%)
    
  M3_Outcomes_Delivered:
    Definición: Valor entregado a destinatarios
    Métricas:
      - Customer_Satisfaction: CSAT score (target: >4.0/5.0)
      - NPS: Net Promoter Score (target: >30)
      - Business_Metrics: Revenue, retention, engagement (contextual)
      - OKR_Completion: % OKRs met (target: 70-80%, NOT 100%)
    
  M4_Team_Health:
    Definición: Sostenibilidad y bienestar
    Métricas:
      - Team_Satisfaction: Survey score (target: >7/10)
      - Turnover_Rate: % exits anual (target: <15%)
      - Utilization: % capacity usado (target: 70-85%, NO >90%)
      - Burnout_Indicators: Hours, PTO usage, sick days
    
  M5_Organizational_Health:
    Definición: Sistema completo (H_Score)
    Ver: A3_Diagnostico.md §3-§4
    Métricas: 11 observables (O1-O8, IN1-IN3)
    Target: H_Score >80 (sostenido 6+ meses)

Relación_H_Score_con_Métricas:
  H_Score = f(11_observables)
  Observables = agregaciones métricas granulares (M1-M4)
  
  Ejemplo:
    O4_Velocity_Baja → alimentado por Cycle_Time, Throughput (M1)
    O2_Churn → alimentado por Turnover_Rate (M4)
```

---

### 9.2 Success Criteria Templates

```yaml
Template_Pilot (Fase 4):
  Quantitative:
    ☐ Cycle_Time: Improvement >20% vs baseline
    ☐ Team_Satisfaction: Score >75/100
    ☐ Quality: No degradation (incident rate estable o mejor)
    ☐ H_Score_Pilot_Teams: +10 pts mínimo
  
  Qualitative:
    ☐ Team_Recommendation: >80% advocate rollout
    ☐ Manager_Champions: Public support
    ☐ No_Critical_Blockers: Todos issues tienen path resolution
  
  Decision:
    IF 4+ quantitative + 3 qualitative → GO
    IF 2-3 quantitative + 2 qualitative → EXTEND
    IF <2 quantitative → PAUSE

Template_Scale (Fase 5):
  Per_Wave:
    ☐ Teams_Success_Rate: >70% teams met criteria
    ☐ Issues_Resolution: >80% resolved <2 semanas
    ☐ No_Regression: H_Score no cae >5 pts
  
  Final (Post Wave-3):
    ☐ H_Score_Improvement: +15-25 pts vs baseline
    ☐ Cycle_Time_Org: -30%+ improvement
    ☐ Team_Satisfaction_Avg: >70/100
    ☐ Turnover_Rate: -20%+ reduction

Template_Sostenibilidad (Fase 6):
  Quarterly:
    ☐ H_Score: Stable >80 (±2 pts acceptable)
    ☐ No_Reversion: <5% teams reverting old ways
    ☐ Continuous_Improvement: 2-3 experiments per team
  
  Handoff_Ready (Mes 24):
    ☐ H_Score: >80 sostenido 2 quarters
    ☐ PMO_Independence: Org opera sin PMO support
    ☐ BAU_Ownership: Managers confident owning process
```

---

### 9.3 Data Collection Protocols

```yaml
Automated_Collection (Preferido):
  
  Source_Systems:
    - Jira/Linear: Cycle time, throughput, WIP
    - GitHub: Deployment frequency, PR metrics
    - Datadog/Grafana: Incident rate, MTTR, uptime
    - Slack/Email: Communication patterns (optional)
  
  Pipeline:
    Extract → Transform → Load → Dashboard
    Frecuencia: Real-time o diaria
    Owner: Data team (post-handoff PMO)
  
  Dashboards:
    - Team-level: Métricas M1-M4 (granular)
    - Org-level: H_Score + Trends (aggregated)
    - Executive: OKRs + ROI (strategic)

Manual_Collection (Si automated no disponible):
  
  Surveys:
    Frecuencia: Semanal (pilot), Mensual (scale/sostenibilidad)
    Tool: Google Forms, Typeform, o similar
    Response_Rate_Target: >80%
    
    Questions_Standard:
      - Satisfaction: "¿Cómo te sientes en tu team?" (1-10)
      - Velocity: "¿Sientes que avanzas rápido?" (1-10)
      - Autonomy: "¿Puedes decidir cómo trabajar?" (1-10)
      - Clarity: "¿Están claras tus prioridades?" (1-10)
      - Support: "¿Tienes support que necesitas?" (1-10)
  
  Entrevistas:
    Frecuencia: Mensual (sample 10-20 personas)
    Duración: 30 min
    Format: Semi-structured (preguntas guía + open-ended)
    Owner: PMO (ejecuta) + Coalition (analiza)
  
  Retrospectivas:
    Frecuencia: Bi-weekly (todas teams)
    Duración: 60 min
    Capture: Action items + Themes recurrentes
    Agregación: PMO identifica patterns org-wide

Data_Quality_Checks:
  ☐ Completitud: >90% data points captured
  ☐ Consistency: Definitions alineadas (no ambigüedad)
  ☐ Actualidad: Lag <7 días (métricas no stale)
  ☐ Accuracy: Spot-checks random sample (validation)
```

---

### 9.4 Reporting Cadence

```yaml
Real-Time_Dashboards:
  Audiencia: Teams + Managers
  Métricas: M1-M4 (flow, quality, health)
  Acción: Self-service, alerts automáticos si thresholds
  
Weekly_Status_Reports:
  Audiencia: PMO + Sponsor
  Contenido:
    - Progress vs plan (% completado)
    - Blockers top 3
    - Metrics snapshot (week-over-week)
    - Next week priorities
  Formato: 1-2 páginas + dashboard link
  
Bi-Weekly_Coalition_Reports:
  Audiencia: Coalition
  Contenido:
    - Metrics trends (2-week window)
    - Issues log (new, resolved, open)
    - Gate readiness (si upcoming)
    - Decisions needed
  Formato: Slide deck (10-15 slides) + discussion
  
Monthly_Exec_Summary:
  Audiencia: C-level
  Contenido:
    - H_Score trend (MoM)
    - Phase progress (Gantt visual)
    - ROI tracking (investment vs benefits)
    - Top wins + Top challenges
  Formato: 1-pager + Executive dashboard
  
Quarterly_QBR:
  Ver: §7.3 (detalle completo)
  
Annual_Retrospectiva:
  Ver: §7.3 (detalle completo)
```

## §10. PLAYBOOKS ESPECIALIZADOS

### 10.1 Por Antipatrón Específico

```yaml
Playbook_AP14_Tech_Debt:
  
  Fase_1_Diagnóstico:
    ☐ Tech debt score actual (survey + code analysis)
    ☐ Cost of delay estimate ($K/mes per 100 eng)
    ☐ Top 3 módulos críticos identificados
  
  Fase_2_Diseño:
    Target: Tech debt score <30 (de actual >50)
    Strategy: 20% rule (P25) + 2 sprints freeze
    Plan:
      - Sprint 1-2: Feature freeze, refactor Module A
      - Sprint 3-4: Refactor Module B
      - Sprint 5+: 20% rule permanent (embedded)
  
  Fase_3_Preparación:
    ☐ Comunicar business case freeze
    ☐ Training: Refactoring patterns, TDD
    ☐ CI/CD quality gates (coverage >80%)
  
  Fase_4_Piloto:
    ☐ 2 teams implement 20% rule (4 semanas)
    ☐ Measure: Tech debt score evolution, velocity recovery
    Success: Debt -30%, Velocity stable o mejor
  
  Fase_5_Scale:
    ☐ Rollout 20% rule todos teams (wave-by-wave)
    ☐ Monitor: Debt score mensual (target <30)
  
  Fase_6_Sostenibilidad:
    ☐ Alert si debt score >30 (regression)
    ☐ Quarterly debt cleanup sprints (proactive)

Playbook_AP01_Silos:
  
  Fase_1_Diagnóstico:
    ☐ Interaction matrix teams (quién habla con quién)
    ☐ Dependency count (handoffs por feature)
    ☐ Interview: Pain points collaboration
  
  Fase_2_Diseño:
    Target: Cross-functional teams (P02)
    Design:
      - 8 teams, cada uno: Eng + Design + Product + QA
      - Co-located (físico o virtual)
      - End-to-end ownership (no handoffs)
  
  Fase_3_Preparación:
    ☐ Comunicar new org chart (transparencia)
    ☐ Training: Cross-functional workflows
    ☐ Address fears (especialización no se pierde)
  
  Fase_4_Piloto:
    ☐ 2 teams transition cross-functional (8 semanas)
    ☐ Measure: Cycle time, handoffs count, satisfaction
    Success: Cycle time -40%, Handoffs -80%
  
  Fase_5_Scale:
    ☐ Rollout 8 teams total (3 waves)
  
  Fase_6_Sostenibilidad:
    ☐ Maintain team stability (low churn)
    ☐ Communities of practice (preserve expertise)

Playbook_AP08_Hero_Culture:
  
  Fase_1_Diagnóstico:
    ☐ Identify heroes (quiénes resuelven todo)
    ☐ Bus factor analysis (knowledge silos)
    ☐ On-call burden distribution (equitable?)
  
  Fase_2_Diseño:
    Target: Distributed ownership (P04, P09)
    Strategy:
      - Pair programming rotation
      - Documentation sprints
      - On-call rotation balanced
      - Hero recognition redirected (team wins, no individual)
  
  Fase_3_Preparación:
    ☐ Training: Pairing, documentation, knowledge sharing
    ☐ Communication: Heroes no penalizados (reframe contribution)
  
  Fase_4_Piloto:
    ☐ 2 teams implement rotation (4 semanas)
    ☐ Measure: Bus factor improvement, on-call equity
  
  Fase_5_Scale:
    ☐ Rollout org-wide
  
  Fase_6_Sostenibilidad:
    ☐ Monitor bus factor (target: >3 per domain crítico)
    ☐ Celebrate team wins (no hero worship)
```

---

### 10.2 Por Contexto Organizacional

```yaml
Context_Startup (<50 personas):
  
  Adjustments:
    - Fases compressed: 6-9 meses total (vs 12-24)
    - Coalition smaller: 4-6 personas (vs 8-12)
    - PMO lean: 1 persona part-time (vs 2-3 FTE)
    - Pilot optional: Si org pequeña, direct rollout viable
  
  Focus:
    - Establish foundations (processes básicos)
    - Scale-ready (no over-engineer)
    - Speed > Perfection

Context_Scaleup (50-500 personas):
  
  Standard: Usar playbook §1-§7 tal cual
  
  Considerations:
    - Pilot crítico (validar antes commitment full)
    - Wave planning cuidadoso (manage disruption)
    - Communication intensive (evitar rumores)

Context_Enterprise (>500 personas):
  
  Adjustments:
    - Fases extended: 18-36 meses (vs 12-24)
    - Sub-waves por BU/geography
    - PMO larger: 5-8 personas (central + embedded)
    - Change management formal (dedicated team)
  
  Challenges:
    - Inertia organizational (status quo fuerte)
    - Political complexity (coaliciones, resistance)
    - Legacy systems (tech debt alto)
  
  Mitigations:
    - Executive sponsorship crítico (remover blockers)
    - Phased BU-by-BU (no org-wide big-bang)
    - External consulting (capacity + expertise)

Context_Regulated (Finance, Health, Gov):
  
  Adjustments:
    - Compliance checks per fase (legal review)
    - Documentation extensive (audit trails)
    - Change approval formal (CABs - Change Advisory Boards)
  
  Timeline: +30-50% vs standard (compliance overhead)
  
  Focus:
    - Risk management (mitigation plans detailed)
    - Auditability (trazabilidad completa)
```

---

### 10.3 Por Nivel H_Score Inicial

```yaml
H_Score_0-30 (Crisis):
  Protocol: Ver §0 Path 1-2 + CORE/08_Crisis_Management.md
  NO usar playbook standard hasta stabilized (H>45)

H_Score_30-45 (Struggling):
  Focus: Stabilization primero, transformation después
  Quick_Wins:
    - Reduce WIP (immediate relief)
    - Stop bleeding (incident triage, on-call rotation)
    - 20% tech debt (velocity recovery)
  Timeline: 6 meses stabilization → 12 meses transformation

H_Score_45-60 (Functional but suboptimal):
  Standard: Playbook §1-§7
  Emphasis: Structured improvement (no urgency extrema)

H_Score_60-75 (Healthy):
  Focus: Incremental excellence
  Adjustments:
    - Low risk tolerance (no disruption)
    - Pilot extensive (validate everything)
    - Emphasize learning (capability building)

H_Score_>75 (High-performing):
  Question: ¿Realmente necesitas transformación?
  Consider:
    - Continuous improvement embedded (Kaizen)
    - Experimentation culture (P06 probabilistic)
    - Avoid disruption (si no está roto, no arreglar)
```

---

### 10.4 ROI Models

```yaml
Investment_Typical (Org 100-500 personas):
  
  Headcount:
    PMO: 2-3 FTE × 18 meses × $150K/año = $405K-$608K
    Backfill: 15% capacity × 100 personas × $120K/año × 0.5 año = $900K
    Total_Headcount: $1.3M-$1.5M
  
  Tools_Infrastructure:
    Feature flags: $50K/año
    CI/CD upgrades: $30K
    Analytics: $20K/año
    Training platforms: $10K
    Total_Tools: $110K
  
  Consulting (Si externa):
    Diagnosis: $50K-$100K
    Design: $100K-$200K
    Execution support: $200K-$400K
    Total_Consulting: $350K-$700K (optional)
  
  Total_Investment: $1.4M-$2.3M (18 meses)

Benefits_Year_1_Post-Implementation:
  
  Velocity_Gain:
    Cycle time -40% → Features +40% faster → $1.5M value
    (Assumes $10M revenue, 15% attributed velocity)
  
  Quality_Improvement:
    Incident rate -50% → Downtime -50% → $300K saved
    (Assumes $600K/año downtime cost actual)
  
  Churn_Reduction:
    Turnover -30% (22% → 15%) → $500K saved
    (Assumes $50K cost per replacement × 10 personas saved)
  
  Tech_Debt_Relief:
    Velocity recovery +20% long-term → $800K/año ongoing
  
  Total_Benefits: $3.1M Year 1

ROI_Calculation:
  Net_Benefit: $3.1M - $2.3M = $800K
  ROI: ($3.1M / $2.3M) - 1 = 35% Year 1
  Payback: 18 meses post-implementation (~30 meses total)
  
  Year_2-3: Benefits compound (velocity, quality, retention)
  IRR_3_Year: ~60-80% típico

Sensitivity_Analysis:
  Conservative (50% benefits): ROI = -30% Year 1, breakeven Year 2
  Aggressive (150% benefits): ROI = 102% Year 1
  
  Conclusion: Positive ROI probable si execution competente
```
