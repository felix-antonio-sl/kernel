# A3_Diagnostico

**VersiÃ³n:** 1.0.0 | **Estado:** Definitivo | **Audiencia:** Consultores, Arquitectos Empresariales, LÃ­deres

---

## Â§1. OVERVIEW FRAMEWORK DIAGNÃ“STICO

### PropÃ³sito

```yaml
Objetivo: Evaluar health organizacional end-to-end mediante KERNEL
Salida: H_Score (0-100) + recomendaciones priorizadas
DuraciÃ³n: 2-4 semanas tÃ­pico (depende org size)
Audiencia_Reporte: C-level, Board (strategic), Managers (tactical)
```

---

### 5 Fases

```
1. PREPARACIÃ“N (3-5 dÃ­as)
   - Definir scope, stakeholders clave, access datos
   
2. RECOLECCIÃ“N_DATOS (5-10 dÃ­as)
   - 11 observables (O1-O8, I1-I3)
   - Entrevistas (20-30 personas)
   - MÃ©tricas sistemas

3. ANÃLISIS (3-5 dÃ­as)
   - Calcular H_Score
   - Identificar antipatrones (AP01-AP35: 30 base + 5 crisis/orchestration)
   - Detectar patrones faltantes (P01-P53: 50 base + 3 emergentes)

4. RECOMENDACIONES (2-3 dÃ­as)
   - Priorizar top 5 iniciativas
   - Roadmap 12 meses
   - Quick wins (30-90 dÃ­as)

5. PRESENTACIÃ“N (1-2 dÃ­as)
   - Executive summary (C-level)
   - Detailed report (managers)
   - Workshop actionable
```

---

## Â§2. PREPARACIÃ“N (FASE 1)

### Checklist Inicio

```yaml
LogÃ­stica:
  â˜ Sponsor C-level identificado (CEO/CTO)
  â˜ Budget aprobado ($X para consultorÃ­a si externa)
  â˜ Timeline acordado (2-4 semanas)
  â˜ NDA firmado si datos sensibles

Access:
  â˜ Acceso sistemas mÃ©tricas (Jira, Git, CI/CD, etc.)
  â˜ Calendario 20-30 entrevistas bloqueado
  â˜ Docs internos (org chart, OKRs, roadmaps)
  â˜ Financials si relevante (revenue, churn, etc.)

Scope:
  â˜ Boundary org (Â¿toda empresa o solo Engineering?)
  â˜ Profundidad (high-level o deep-dive por dominio)
  â˜ Focus areas si dirigido (ej: solo OperaciÃ³n, solo IA)
```

---

### Template Kick-Off

```yaml
Meeting_Duration: 90 min
Attendees: Sponsor, stakeholders clave (5-8 personas)

Agenda:
  1. Intro KERNEL framework (15 min)
  2. Objetivos diagnÃ³stico (10 min)
  3. MetodologÃ­a (11 observables, H_Score) (20 min)
  4. Timeline & logistics (10 min)
  5. Q&A (20 min)
  6. Next steps (15 min)

Outputs:
  - Lista entrevistados (roles, fechas)
  - Accesos sistemas confirmados
  - Questions especÃ­ficas sponsor quiere responder
```

---

## Â§3. RECOLECCIÃ“N DATOS (FASE 2)

### 11 Observables: Data Sources

| Observable | Source Primaria | Source Secundaria | Tooling TÃ­pico |
|-----------|-----------------|-------------------|----------------|
| **O1 (Demanda)** | Jira backlog, sales pipeline | Entrevistas PMs | Jira, Salesforce |
| **O2 (Valor)** | NPS, CSAT, churn metrics | Customer interviews | Qualtrics, Mixpanel |
| **O3 (Capacidad)** | Headcount, utilization | Entrevistas managers | HR system, Jira |
| **O4 (Eventos)** | Incident logs, regulatory changes | Entrevistas CTO | PagerDuty, legal |
| **O5 (Restricciones)** | Compliance audits, SLA breaches | Entrevistas compliance | SOC2 reports |
| **O6 (Competencia)** | Market research, win/loss data | Entrevistas sales | G2, Crunchbase |
| **O7 (Dependencias)** | Vendor contracts, integration logs | Entrevistas architects | Contract mgmt |
| **O8 (Calidad Info)** | Data quality reports, trust surveys | Entrevistas data team | DBT, Alation |
| **I1 (Velocidad Decisional)** | Decision log, escalations | Entrevistas managers | Custom tracking |
| **I2 (Salud Talento)** | Engagement surveys, turnover | Entrevistas HR | Culture Amp, Lattice |
| **I3 (Eficiencia Flujo)** | Cycle time, throughput, WIP | Git, Jira | LinearB, Jellyfish |

---

### Template Entrevista

```yaml
DuraciÃ³n: 45-60 min
Formato: Semi-estructurado (preguntas guÃ­a + follow-up)

Secciones:
  1. Contexto (5 min):
     - Rol, tenure, team size
  
  2. Estado actual (15 min):
     - "Â¿CuÃ¡les son tus top 3 challenges hoy?"
     - "Â¿QuÃ© funciona bien?"
  
  3. Por dominio (20 min):
     - Arquitectura: "Â¿Es clara la estructura org? Â¿QuiÃ©n decide quÃ©?"
     - PercepciÃ³n: "Â¿Tienes datos confiables para decisiones?"
     - DecisiÃ³n: "Â¿CÃ³mo priorizas? Â¿QuÃ© tan rÃ¡pido decides?"
     - OperaciÃ³n: "Â¿CÃ³mo mides velocity? Â¿Tech debt es manejable?"
  
  4. IA (si aplica) (10 min):
     - "Â¿Usan IA/ML? Â¿En quÃ© modo (M1-M6)?"
     - "Â¿ConfÃ­an en outputs IA?"
  
  5. Cierre (10 min):
     - "Si tuvieras varita mÃ¡gica, Â¿quÃ© cambiarÃ­as?"
     - "Â¿Algo mÃ¡s importante mencionar?"

Notas:
  - Grabar (con permiso) para accuracy
  - Confidencialidad: feedback anÃ³nimo en reporte
```

---

### Matriz Roles Ã— Preguntas

| Rol | Focus Preguntas |
|-----|-----------------|
| **C-level** | Estrategia, OKRs, presupuesto, top risks |
| **VP/Directors** | PriorizaciÃ³n portfolio, resource allocation, coordination cross-team |
| **Managers** | Team health, velocity, blockers, tech debt |
| **ICs (Individual Contributors)** | Herramientas, process pain points, autonomy |
| **Product** | Roadmap, discovery, customer feedback |
| **Data/Analytics** | Data quality, lineage, trust |

---

## Â§4. ANÃLISIS (FASE 3)

### CÃ¡lculo H_Score

**Ver fÃ³rmula completa:** `DOMINIOS/D2_Percepcion.md` Â§4

```yaml
Paso_1: Score cada observable 0-100
Paso_2: Aplicar ponderaciones
  H = 0.12*O1 + 0.15*O2 + 0.10*O3 + 0.08*O4 + 
      0.10*O5 + 0.10*O6 + 0.08*O7 + 0.07*O8 +
      0.08*I1 + 0.08*I2 + 0.04*I3

Paso_3: InterpretaciÃ³n
  90-100: Excelente
  75-89: Bueno
  60-74: AtenciÃ³n requerida
  <60: CrÃ­tico
```

---

### DetecciÃ³n Antipatrones

```yaml
Por_Cada_AntipatrÃ³n (AP01-AP35):
  1. Check sÃ­ntomas (mÃ©tricas + entrevistas)
  2. Si 2+ sÃ­ntomas presentes â†’ AP confirmado
  3. Severity: ğŸ”´ CrÃ­tico / ğŸŸ¡ Alto / ğŸŸ¢ Moderado
  
  Antipatrones_v1.3_Nuevos:
    - AP31 (Crisis Theater): Declarar crisis sin cambiar governance
    - AP32 (Forcing Transformation Unprepared): Transform sin readiness R1-R5
    - AP33 (Transforming During Crisis): Transform cuando H_Score<45
    - AP34 (No Orchestration): N agents compiten, conflicts sin coordinator
    - AP35 (Over-Orchestration): Orchestrator bottleneck, agents await approval

PriorizaciÃ³n:
  - CrÃ­ticos first (AP con severidad ğŸ”´)
  - Ordenar por impact (Cost of Delay Ã— Probability)

Ejemplo:
  AP14 (Tech Debt Perpetuo):
    âœ… SÃ­ntoma 1: Tech debt score 68 (threshold <30)
    âœ… SÃ­ntoma 2: Velocity -62% vs baseline
    âœ… SÃ­ntoma 3: Incident rate +200%
    â†’ AP14 confirmado, Severity ğŸ”´
    â†’ Cost of Delay: $250K/mes (per 100 eng)
    â†’ Top priority remediation
```

---

### Patrones Faltantes

```yaml
Por_Cada_PatrÃ³n (P01-P53):
  1. Â¿EstÃ¡ implementado?
  2. Si NO y contexto aplica â†’ Gap identificado
  3. ROI_Estimado patrÃ³n (Ver Â§8 A1_Patrones)

Ejemplo:
  P23 (Feature Flags):
    Estado: No implementado
    Contexto: Deploy frequency <1/mes, rollback 30+ min
    â†’ PatrÃ³n aplica
    ROI: Deploy frequency 2Ã—/dÃ­a, rollback <1 min
    â†’ Recomendar implementar (quick win)
```

---

### EvaluaciÃ³n Awareness Levels (S1-S3)

```yaml
Objetivo:
  Diagnosticar madurez percepciÃ³n en 3 niveles cognitivos (CORE/02 Â§2, D2 Â§5)

Checklist_Por_Level:

S1_DETECT (Percibir):
  â˜ Â¿Org captura metrics raw de systems crÃ­ticos?
  â˜ Â¿Dashboards disponibles para observables O1-O8, I1-I3?
  â˜ Â¿Telemetry real-time o near-real-time?
  â˜ Â¿Logs aggregated y searchable (ELK, Splunk)?
  
  Score_S1 (0-100):
    = (% systems_monitored + dashboard_coverage + telemetry_quality) / 3
  
  Target: >80
  Gap_TÃ­pico: M1 agents faltantes (monitoring automated)

S2_COMPREHEND (Comprender):
  â˜ Â¿H_Score calculado automÃ¡ticamente? (11 observables â†’ 1 metric)
  â˜ Â¿Alerting context-aware? (no solo raw thresholds)
  â˜ Â¿Observables interpretados con contexto business?
  â˜ Â¿Pattern recognition automated? (anomaly detection)
  
  Score_S2 (0-100):
    = (h_score_automated + alerting_quality + pattern_detection) / 3
  
  Target: >70
  Gap_TÃ­pico: M2 agents faltantes (intelligent alerting, synthesis)

S3_PROJECT (Proyectar):
  â˜ Â¿Forecasting trends implementado? (revenue, churn, capacity)
  â˜ Â¿Crisis thresholds monitoreados? (H_Score<45 trigger alerts)
  â˜ Â¿Scenario planning tools available? (Monte Carlo, what-if)
  â˜ Â¿Predictive models en producciÃ³n? (churn, demand, failures)
  
  Score_S3 (0-100):
    = (forecasting + crisis_monitoring + scenarios + predictive_models) / 4
  
  Target: >60
  Gap_TÃ­pico: M3 agents faltantes (predictive analytics, simulation)

Awareness_Maturity_Overall:
  Score = (S1 Ã— 0.4) + (S2 Ã— 0.35) + (S3 Ã— 0.25)
  
  InterpretaciÃ³n:
    >80: Excelente - Full spectrum awareness
    60-80: Bueno - S1+S2 strong, S3 emergente
    40-60: AtenciÃ³n - Solo S1, gaps S2-S3
    <40: CrÃ­tico - Awareness bÃ¡sica insuficiente
```

---

### EvaluaciÃ³n Decision Modes (D1-D4)

```yaml
Objetivo:
  Diagnosticar madurez decisional en 4 modos complejidad (CORE/02 Â§3, D3 Â§6)

Checklist_Por_Mode:

D1_DIRECT_FEEDBACK (AutomÃ¡tica):
  â˜ Â¿QuÃ© decisiones automÃ¡ticas existen? (list 10+)
  â˜ Ejemplos: Autoscaling, circuit breakers, fraud rules simple
  â˜ Â¿Bounded autonomy clara? (M6 con limits explÃ­citos)
  
  Automation_D1_Rate:
    = # decisiones_D1_automated / # decisiones_D1_posibles
    Target: >60%
  
  Gap: Opportunities para M6 automation (thermostat-style loops)

D2_RULE_BASED (Condicional):
  â˜ Â¿Business rules explÃ­citas? Â¿Documentadas?
  â˜ Â¿Approval workflows automated? (>$10K require VP)
  â˜ Â¿Rules engine en uso? (Drools, decision tables)
  
  Rules_Coverage_D2:
    = # business_rules_documented / # critical_decision_types
    Target: >90%
  
  Gap: Rules engines faltantes, rules tribal knowledge (M4-M5)

D3_ASSOCIATIVE (Expertise-based):
  â˜ Â¿ML models en producciÃ³n? Â¿QuÃ© deciden?
  â˜ Â¿Human validation required? (M4 control)
  â˜ Â¿Model monitoring? (drift, accuracy, fairness)
  
  ML_Production_D3:
    = # ML_models_serving_decisions
    Target: 5-10 models (depends on org size)
  
  Gap: ML/AI underutilized, no human-in-loop validation

D4_KNOWLEDGE_BASED (AnalÃ­tica):
  â˜ Â¿Strategic planning structured? (OKRs, roadmaps)
  â˜ Â¿Simulation tools available? (Monte Carlo, scenarios)
  â˜ Â¿Decision latency acceptable? (<7 days strategic)
  
  Decision_Latency_D4:
    = Avg time desde problem identified â†’ decision made
    Target: <7 days (strategic), <24hrs (tactical)
  
  Gap: Decision support tools (M2-M3 enable), analysis paralysis

Decision_Maturity_Overall:
  Automation_Score = % decisiones repeatables que estÃ¡n automated
  
  Benchmark:
    >50%: Excelente - Alta automation apropiada
    30-50%: Bueno - Balance automation/human
    15-30%: AtenciÃ³n - Underautomated
    <15%: CrÃ­tico - Manual decision overload
```

---

## Â§5. RECOMENDACIONES (FASE 4)

### Framework PriorizaciÃ³n

```yaml
Score_Iniciativa = (
  0.40 Ã— Impact_Estimado +
  0.25 Ã— Urgencia +
  0.20 Ã— Feasibility +
  0.15 Ã— Strategic_Fit
)

Impact_Estimado:
  - H_Score mejora esperada (ej: +15 pts)
  - ROI financiero ($ savings o revenue)

Urgencia:
  - Severity antipatrÃ³n (ğŸ”´=100, ğŸŸ¡=60, ğŸŸ¢=30)
  - Deadline externo (regulaciÃ³n, competitor)

Feasibility:
  - R1-R5 preparaciÃ³n score (Ver DOMINIOS/D3)
  - Complejidad tÃ©cnica

Strategic_Fit:
  - Alignment OKRs existentes
  - Sponsor C-level disponible
```

---

### Template RecomendaciÃ³n

```yaml
Iniciativa_ID: REC-XX
TÃ­tulo: [Nombre descriptivo]
AntipatrÃ³n_Mitigado: [APXX] O PatrÃ³n_Implementado: [PXX]

Problema_Actual:
  - [SÃ­ntomas observados]
  - [MÃ©tricas actuales vs target]

SoluciÃ³n_Propuesta:
  - [PatrÃ³n a implementar]
  - [Cambios especÃ­ficos org/tech/process]

Beneficios_Esperados:
  - H_Score: +X puntos (Y â†’ Z)
  - MÃ©tricas especÃ­ficas: [ej: cycle time 14d â†’ 5d]
  - ROI: $X ahorros/aÃ±o

Effort_Estimado:
  - DuraciÃ³n: X semanas/meses
  - Headcount: Y personas
  - Budget: $Z

Riesgos:
  - [Riesgo 1 + mitigaciÃ³n]
  - [Riesgo 2 + mitigaciÃ³n]

PreparaciÃ³n_R1-R5:
  - R1 (Momentum): XX/100
  - R2 (Capabilities): YY/100
  - R3 (Forces): ZZ/100
  - R4 (Drivers): AA/100
  - R5 (Catalysts): BB/100
  - Score Total: CC/100 (GO / GO CONDITIONAL / NO-GO)

Prioridad: Alta / Media / Baja
Timeline: Q1 2025 / Q2 2025 / etc.
Owner_Propuesto: [Rol]
```

---

### Top 5 Iniciativas TÃ­picas

```yaml
1. Remediar_Tech_Debt (si AP14 presente):
   - Implementar 20% rule capacity health
   - Quick win visible (velocity +40% en 8 semanas)

2. Implementar_Feature_Flags (si AP18):
   - Deploy â‰  Release
   - ROI: Deploy frequency 10Ã—, rollback <1min

3. OKRs_Bottom-Up (si AP19, AP20):
   - Outcomes no outputs
   - Alignment strategy â†” execution

4. Cross-Functional_Teams (si AP03):
   - Eliminar silos
   - Cycle time -50%

5. Anomaly_Detection_IA (si O8 bajo):
   - M2 mode alertas automÃ¡ticas
   - Proactive vs reactive
```

---

## Â§6. PRESENTACIÃ“N (FASE 5)

### Executive Summary (C-level, 30 min)

```yaml
Slide_1: H_Score Overall
  - Score: XX/100 (Bueno/AtenciÃ³n/CrÃ­tico)
  - Trend: vs Q anterior si disponible
  - Top 3 fortalezas
  - Top 3 gaps

Slide_2: Observables Breakdown
  - 11 observables visual (radar chart)
  - Rojos: [OX, IY] crÃ­ticos
  - Verdes: [OZ] excelentes

Slide_3: Antipatrones CrÃ­ticos
  - APXX: [Nombre], Cost $X/mes, Severity ğŸ”´
  - APYY: [Nombre], Cost $Y/mes, Severity ğŸ”´
  - Total: Z antipatrones, $W/mes cost

Slide_4: Top 5 Recomendaciones
  - REC-01: [TÃ­tulo], Impact +X pts H_Score, ROI $Y
  - REC-02: ...
  - REC-03: ...
  - REC-04: ...
  - REC-05: ...

Slide_5: Roadmap 12 Meses
  - Q1: Quick wins (REC-01, REC-03)
  - Q2: Foundations (REC-02)
  - Q3-Q4: Transformational (REC-04, REC-05)

Slide_6: Investment Requerido
  - Budget: $X total
  - Headcount: Y personas dedicated
  - Timeline: Z meses
  - ROI: AÃ— en aÃ±o 1

Slide_7: Next Steps
  - Aprobar budget
  - Asignar owners iniciativas
  - Kick-off REC-01 (quick win)
```

---

### Detailed Report (Managers, 50-80 pÃ¡ginas)

```yaml
Estructura:
  1. Executive Summary (5 pgs)
  2. MetodologÃ­a (3 pgs)
  3. Findings (30 pgs)
     - Por dominio (Arquitectura, PercepciÃ³n, DecisiÃ³n, OperaciÃ³n)
     - 11 observables detallados
     - Antipatrones identificados
  4. Recomendaciones (20 pgs)
     - Top 5 detalladas
     - Otras 10 priorizadas
  5. Appendix (20 pgs)
     - Raw data
     - Interview quotes (anÃ³nimos)
     - Benchmarks industry

Formato:
  - PDF + Excel (datos raw para analysis)
  - Confidencial (no share fuera org sin approval)
```

---

## Â§7. EJEMPLO COMPLETO: CASO FICTICIO "TechCorp"

### Contexto

```yaml
Org: TechCorp (B2B SaaS, 150 personas, 80 eng)
DuraciÃ³n_DiagnÃ³stico: 3 semanas
Sponsor: CTO
Objetivo: Entender por quÃ© velocity cayÃ³ 40% Ãºltimo aÃ±o
```

---

### H_Score Calculado

```yaml
Observables:
  O1_Demanda: 75 (backlog creciendo sano)
  O2_Valor: 55 (NPS 28, churn 12% - CRÃTICO)
  O3_Capacidad: 65 (utilization 92%, capacity free 8% - lÃ­mite)
  O4_Eventos: 85 (sin disrupciones mayores)
  O5_Restricciones: 90 (compliance OK)
  O6_Competencia: 60 (perdiendo vs competitor X)
  O7_Dependencias: 80 (vendors estables)
  O8_Calidad_Info: 70 (data quality 75%, OK)
  I1_Velocidad_Decisional: 45 (TTD 18 dÃ­as - CRÃTICO)
  I2_Salud_Talento: 50 (turnover 22%, engagement 55 - CRÃTICO)
  I3_Eficiencia_Flujo: 40 (cycle time 16 dÃ­as, efficiency 18% - CRÃTICO)

H_Score = 0.12*75 + 0.15*55 + 0.10*65 + 0.08*85 + 
          0.10*90 + 0.10*60 + 0.08*80 + 0.07*70 +
          0.08*45 + 0.08*50 + 0.04*40
        = 9 + 8.25 + 6.5 + 6.8 + 9 + 6 + 6.4 + 4.9 + 3.6 + 4 + 1.6
        = 66.05/100 â†’ ATENCIÃ“N REQUERIDA
```

---

### Antipatrones Detectados

```yaml
CrÃ­ticos (ğŸ”´):
  - AP14 (Tech Debt Perpetuo):
      SÃ­ntomas: Velocity -40%, tech debt score 72, incident rate +180%
      Cost: $200K/mes
  
  - AP09 (Handoff Hell):
      SÃ­ntomas: 9 handoffs deploy process, cycle time 16 dÃ­as, efficiency 18%
      Cost: $120K/mes

Altos (ğŸŸ¡):
  - AP03 (Silos Profundos):
      SÃ­ntomas: Frontend/Backend/QA teams separados, "not my job" culture
  
  - AP08 (WIP Sin LÃ­mite):
      SÃ­ntomas: WIP 42 items (team 20 eng), context switching alto
  
  - AP19 (Output Disguised):
      SÃ­ntomas: OKRs "Launch 8 features", no outcomes medibles

Total_Cost_of_Delay: ~$320K/mes + opportunity cost churn alto
```

---

### Top 5 Recomendaciones

```yaml
REC-01 (Prioridad ALTA):
  TÃ­tulo: "Implementar 20% Rule Tech Debt"
  AntipatrÃ³n: AP14
  Impact: H_Score +8 pts, Velocity +35%
  Effort: 2 sprints setup
  ROI: $150K/mes (velocity recovery)
  Timeline: Inicio inmediato
  Owner: VP Engineering

REC-02 (Prioridad ALTA):
  TÃ­tulo: "Cross-Functional Feature Teams"
  AntipatrÃ³n: AP03, AP09
  PatrÃ³n: P01 (Feature Teams)
  Impact: H_Score +12 pts, Cycle time 16d â†’ 6d
  Effort: 8 semanas reorg
  ROI: $180K/mes
  Timeline: Q1 2025
  Owner: CTO
  PreparaciÃ³n_R1-R5: 72/100 (GO CONDITIONAL - need address forces)

REC-03 (Prioridad ALTA):
  TÃ­tulo: "WIP Limits Kanban"
  AntipatrÃ³n: AP08
  PatrÃ³n: P15
  Impact: H_Score +5 pts, Cycle time -30%
  Effort: 2 semanas
  ROI: $60K/mes
  Timeline: Quick win (30 dÃ­as)
  Owner: Eng Managers

REC-04 (Prioridad MEDIA):
  TÃ­tulo: "OKRs Bottom-Up Outcomes"
  AntipatrÃ³n: AP19
  PatrÃ³n: P29
  Impact: H_Score +4 pts, Alignment strategy â†” execution
  Effort: 1 quarter rollout
  ROI: Qualitativo (mejor priorizaciÃ³n)
  Timeline: Q2 2025
  Owner: CPO

REC-05 (Prioridad MEDIA):
  TÃ­tulo: "Churn Prediction ML (M2)"
  Observable: O2 bajo (churn 12%)
  PatrÃ³n: P39
  Impact: H_Score +6 pts (O2: 55 â†’ 75), Churn 12% â†’ 7%
  Effort: 4 meses (hire DS, build model)
  ROI: $200K/aÃ±o (churn reduction)
  Timeline: Q2-Q3 2025
  Owner: Head of Data
```

---

### Roadmap 12 Meses

```
Q1_2025 (Meses 1-3):
  - REC-01: 20% rule tech debt (quick win)
  - REC-03: WIP limits (quick win)
  - REC-02: Pilot cross-functional 2 teams

Q2_2025 (Meses 4-6):
  - REC-02: Rollout cross-functional 8 teams total
  - REC-04: OKRs bottom-up Q3 planning
  - REC-05: Start churn prediction (hire, data prep)

Q3_2025 (Meses 7-9):
  - REC-05: Deploy churn prediction M2 pilot
  - Consolidate gains REC-01,02,03
  - Measure H_Score (esperado: 66 â†’ 78+)

Q4_2025 (Meses 10-12):
  - REC-05: Scale churn prediction all customers
  - Retrospectiva aÃ±o, plan 2026
  - Target H_Score >80 EOY
```

---

## Â§8. HERRAMIENTAS & TEMPLATES

### Plantillas Disponibles

```yaml
Templates_Disponibles:
  - Kick-off deck (PPT)
  - Interview guide (Word)
  - Data collection spreadsheet (Excel)
  - H_Score calculator (Excel con fÃ³rmulas)
  - Recommendation template (Word)
  - Executive summary deck (PPT)
  - Detailed report outline (Word)

UbicaciÃ³n: REFERENCIA/Templates/
```

---

## Â§9. ENERGY FLOW ANALYSIS

### Concepto

```yaml
DefiniciÃ³n:
  Energy = tiempo, atenciÃ³n, esfuerzo invertido por staff
  
  Productive_Energy: Invertida en value creation para clientes
  Dissipated_Energy: Invertida en fricciÃ³n interna, rework, polÃ­tica
  
Fundamento:
  Organizaciones sanas minimizan dissipation
  Organizaciones enfermas gastan >50% energy en fricciÃ³n interna
```

---

### Framework DiagnÃ³stico

```yaml
Proceso:
  1. Map_Time_Investment: Â¿DÃ³nde staff realmente gasta tiempo?
  2. Categorize_Activities:
     - Value_Creation: Trabajo directo para clientes/productos
     - Necessary_Coordination: Meetings/sync esenciales
     - Waste: FricciÃ³n, rework, polÃ­tica, handoffs innecesarios
  3. Identify_Bottlenecks: DÃ³nde energy se acumula (waiting)
  4. Identify_Friction_Points: DÃ³nde energy se disipa (waste)
  5. Trace_to_Root_Causes: Estructura o dynamics causantes

MÃ©trica_Clave:
  Energy_Efficiency = Productive_Energy / Total_Energy
  Target: >60% (healthy), 40-60% (medio), <40% (crÃ­tico)
```

---

### Indicadores Energy Dissipation

```yaml
1. Excessive_Coordination_Meetings:
   SÃ­ntoma: >30% tiempo semanal en meetings coordinaciÃ³n
   Causa_Root: Boundaries difusos (viola P2 D1), silos sin interfaces
   
2. Repeated_Discussions_Without_Resolution:
   SÃ­ntoma: Mismo issue discutido 3+ veces sin decisiÃ³n
   Causa_Root: Decision rights unclear (viola P1 D1)
   
3. Escalations_for_Routine_Decisions:
   SÃ­ntoma: >20 escalaciones/semana a C-level
   Causa_Root: CentralizaciÃ³n excesiva (viola P7 D1, P6 Autonomy)
   
4. Rework_Due_to_Unclear_Requirements:
   SÃ­ntoma: >25% trabajo re-hecho post feedback
   Causa_Root: Handoff hell (viola P5 D1), communication breakdown
   
5. Conflict_Resolution_Consuming_Mgmt_Time:
   SÃ­ntoma: Managers gastan >20% tiempo resolviendo conflictos
   Causa_Root: Domain overlaps (viola P2 D1), conflictos interÃ©s (viola P9 D1)
   
6. Politics_and_Relationship_Management:
   SÃ­ntoma: Staff gastan tiempo "managing up" vs executing
   Causa_Root: Blame culture (no P10), misaligned incentivos
```

---

### Energy Flow Map (Template)

```yaml
Activity_Categories:
  
  Value_Creation (Target >60%):
    - Coding/designing/building productos
    - Customer support directo
    - Sales/marketing a clientes
    - Research/innovation
  
  Necessary_Coordination (Target 20-30%):
    - Sprint planning, standups, retros (si aportan valor)
    - Cross-team sync esencial
    - 1:1s manager-report
    - Architecture reviews necesarios
  
  Waste_Friction (Target <10%):
    - Meetings sin agenda/outcomes
    - Rework evitable
    - Waiting for approvals/handoffs
    - Resolving conflicts estructurales
    - BÃºsqueda informaciÃ³n (tribal knowledge)
    - Politics/CYA behaviors

Ejemplo_Healthy:
  Value: 65% | Coordination: 25% | Waste: 10%
  â†’ Energy efficiency 65%

Ejemplo_Unhealthy:
  Value: 35% | Coordination: 35% | Waste: 30%
  â†’ Energy efficiency 35%, friction crÃ­tica
```

---

### ConexiÃ³n Observables

```yaml
Energy_Dissipation conecta con:
  - I3 (Eficiencia Flujo): Flow efficiency = productive energy / cycle time
  - I1 (Velocidad Decisional): Decision delays = energy waiting
  - O7 (Dependencias): External dependencies = coordination overhead
  
Uso_DiagnÃ³stico:
  Si I3 <50 â†’ Ejecutar Energy Flow Analysis
  â†’ Identificar categorÃ­as waste especÃ­ficas
  â†’ Trace to structural root causes (P1-P10 violations)
```

---

## Â§10. CONFLICT PATTERN ANALYSIS

### Concepto

```yaml
Premisa:
  Conflict NO inherentemente malo
  Conflict = informaciÃ³n sobre problemas estructurales/dinÃ¡micos
  
Tipos_Conflict:
  
  Healthy_Conflict:
    - Disagreement sobre mejor approach a shared goal
    - Task conflict (cÃ³mo hacer X mejor)
    - Constructive debate
    - Resuelto colaborativamente
  
  Unhealthy_Conflict:
    - Competition por recursos, territorio, crÃ©dito
    - Relationship conflict (personal)
    - Political maneuvering
    - Resuelto por power, no merit
  
  Toxic_Conflict:
    - Unresolved conflicts que festeran
    - Passive-aggressive behaviors
    - Sabotage, blame, CYA
    - Spreads y contamina org culture
```

---

### Conflict Topology Mapping

```yaml
Proceso:
  1. Map_Recurring_Conflicts:
     - QuiÃ©n conflicts con quiÃ©n
     - Sobre quÃ© (resources, decisions, territory, credit)
     - Frecuencia (semanal, mensual, ocasional)
  
  2. Identify_Conflict_Clusters:
     - Groups que frecuentemente conflict
     - Departments con alta tensiÃ³n
     - Interfaces problemÃ¡ticas
  
  3. Analyze_Conflict_Causes:
     - Domain overlap (P2 D1 violation)
     - Resource competition (governance weakness)
     - Misaligned incentivos (individual vs team metrics)
     - Authority-accountability mismatch (P1 D1 violation)
     - Conflicts of interest (P9 D1 violation)
  
  4. Trace_to_Structural_Problems:
     - Boundaries unclear â†’ Redefinir domains
     - Shared resources â†’ Governance process
     - Misaligned goals â†’ Restructure OKRs
```

---

### Conflict Resolution Patterns

```yaml
Healthy_Pattern:
  - Conflicts resolved at lowest level
  - Parties involucradas resuelven directamente
  - Manager facilita, no decide
  - Process: Identify shared goal â†’ Explore options â†’ Consensus
  - Timeframe: DÃ­as, no semanas
  
Unhealthy_Pattern:
  - Conflicts escalated immediately
  - Executives become bottleneck (decide todo)
  - Parties evitan confrontation, esperan escalation
  - Process: Complain to boss â†’ Boss decides â†’ Resentment
  - Timeframe: Semanas, meses
  
Toxic_Pattern:
  - Conflicts not resolved, fester
  - Passive-aggressive behavior
  - Work-arounds en lugar de resolution
  - Trust erodes, collaboration stops
  - Culture contamination spreads
```

---

### Conflict Diagnosis Template

```yaml
Conflict_ID: [Unique identifier]
Parties: [Who vs Who]
Subject: [What about - resources, decision, territory, etc.]
Frequency: [Weekly, Monthly, Once]
Type: [Healthy, Unhealthy, Toxic]

Root_Cause_Hypothesis:
  Structural:
    - [ ] Domain overlap (P2 D1)
    - [ ] Authority mismatch (P1 D1)
    - [ ] Conflict of interest (P9 D1)
    - [ ] Conway mismatch (P4 D1)
  
  Dynamic:
    - [ ] Misaligned incentivos
    - [ ] Resource competition
    - [ ] Information hoarding
    - [ ] Blame culture (violates P10)

Resolution_Pattern: [Healthy/Unhealthy/Toxic]

Recommended_Fix:
  If_Structural: [Reorg, clarify boundaries, split roles]
  If_Dynamic: [Governance process, shared OKRs, blameless postmortems]

Ejemplo:
  Conflict_ID: C-2024-015
  Parties: Product Team A vs Platform Team
  Subject: Platform changes breaking Product features sin notice
  Frequency: Weekly
  Type: Unhealthy
  
  Root_Cause: Boundary unclear (P2 D1) + No interface contract
  Resolution_Pattern: Unhealthy (escalated a CTO cada vez)
  
  Fix: 
    - Structural: Definir API contract formal (SLA, versioning)
    - Dynamic: Platform â†’ Product notification 2 weeks antes breaking changes
    - Governance: Monthly sync Product-Platform roadmaps
```

---

### ConexiÃ³n Principios

```yaml
Conflict_Patterns revelan violaciones:
  
  Territorial_Disputes â†’ P2 D1 (Boundaries claros) violation
  Finger_Pointing â†’ P1 D1 (Authority-Accountability match) violation
  "Not_My_Job" â†’ P5 D1 (Minimize Handoffs) violation
  Innovation_Blocked â†’ P9 D1 (Avoid Conflicts Interest) violation
  Silos â†’ P10 (Culture Emergence) - estructura genera cultura silo
  
Uso_DiagnÃ³stico:
  Map conflicts â†’ Identify patterns â†’ Trace to principle violations
  â†’ Structural fix (reorg) or Dynamic fix (governance)
```

---

## Referencias Cruzadas

- **11 Observables:** `DOMINIOS/D2_Percepcion.md`
- **H_Score calculation:** `DOMINIOS/D2_Percepcion.md` Â§4
- **10 Principios Estructurales:** `DOMINIOS/D1_Arquitectura.md` Â§1
- **Culture Emergence (P10):** `CORE/00_Manifiesto.md` Â§3
- **Antipatrones:** `APLICACION/A2_Antipatrones.md`
- **Patrones:** `APLICACION/A1_Patrones.md`
- **PreparaciÃ³n R1-R5:** `DOMINIOS/D3_Decision.md` Â§3
- **ImplementaciÃ³n roadmap:** `APLICACION/A4_Implementacion.md`
- **MediciÃ³n:** `APLICACION/A5_Medicion.md`
